(()=>{var e={1993:e=>{function n(e){return Promise.resolve().then((()=>{var n=new Error("Cannot find module '"+e+"'");throw n.code="MODULE_NOT_FOUND",n}))}n.keys=()=>[],n.resolve=n,n.id=1993,e.exports=n},9594:(e,n,t)=>{"use strict";t.d(n,{F:()=>l,_:()=>o});var r=t(7632);const a=[{Вопросы:"Что такое прогаммное обеспечение",Ответы:"Программное обеспечение – совокупность компьютерных программ и связанных с ними данных, которая содержит инструкции по указанию компьютеру, что и как делать. ПО относится к одной или нескольким компьютерным программам и данным, хранящимся в хранилище компьютера для определенных целей."},{Вопросы:"Что включает в себя разработка ПО",Ответы:"Разработка ПО включает в себя:\n1) технология проектирования программ (например, нисходящее проектирование, структурное и объектно-ориентированное проектирование и др.);\n2) методы тестирования программ;\n3) методы доказательства правильности программ;\n4) анализ качества работы программ;\n5) документирование программ;\n6) разработка и использование программных средств, облегчающих процесс проектирования программного обеспечения.  "},{Вопросы:"Что такое программа",Ответы:"Программа – описание на формальном языке, «понятном» компьютеру, последовательности действий, которые необходимо выполнить над данными для решения поставленной задачи."},{Вопросы:"Уровни программного обеспечения",Ответы:"Уровни программного обеспечения представляют собой иерархическую конструкцию. Каждый уровень опирается на ПО предшествующих уровней \nБазовый уровень - самый низкий уровень ПО. Он отвечает за взаимодействие с базовыми аппаратными средствами. Базовые программные средства входят в состав базового оборудования и хранятся в специальных микросхемах, называемых постоянными запоминающими устройствами (ПЗУ). Программы и данные записываются («прошиваются») в микросхемы ПЗУ на этапе производства и не могут быть изменены в процессе эксплуатации.  \nИнструментальный уровень (трансляторы и компиляторы языков программирования, системы программирования). Создание программ обеспечивают, текстовые редакторы, среды разработки. Трансляторы и компиляторы осуществляют преобразование созданных на языке высоко уровня программ в корректный набор машинных кодов.\nСистемный уровень. Переходный уровень. Программы, работающие на этом уровне, обеспечивают взаимодействие прочих программ компьютерной системы с программами базового уровня и непосредственно с аппаратным обеспечением. \nСлужебный уровень. ПО этого уровня взаимодействует как с программами базового уровня, так и с программами системного уровня. Основное назначение служебных программ (утилит) состоит в автоматизации работ по проверке, наладке и настройке имеющихся программно-аппаратных ресурсов. Во многих случаях они используются для расширения или улучшения функций системных программ \nПрикладной уровень. ПО прикладного уровня представляет собой комплекс прикладных программ, с помощью которых на данном рабочем месте выполняются конкретные задания. Спектр таких заданий очень широк – от производственных до творческих и развлекательно - обучающих."},{Вопросы:"Какими свойствами обладает сложная программа",Ответы:"-Программа решает одну или несколько связанных задач; \n-существенно, чтобы программа была удобной в использовании. В частности, она должна включать достаточно полную и понятную документацию, возможно, также специальную документацию для администраторов, а также набор документов для обучения работе с программой; \n-низкая производительность программы на реальных данных приводит к значимым потерям для пользователей; \n-неправильная работа программы наносит ощутимый ущерб пользователям и другим организациям и лицам, даже если сбои происходят не слишком часто; \n-для выполнения своих задач программа должна взаимодействовать с другими программами и программно-аппаратными системами и обеспечивать работу на разных платформах; \n-пользователи, работающие с программой, приобретают дополнительные выгоды от того, что программа развивается, в нее вносятся новые функции и устраняются ошибки; \n-в разработку программы вовлечено значительное количество людей (более 5-ти человек); \n-большая программа имеет намного большее количество ее возможных пользователей по сравнению с небольшими программами, и еще больше тех лиц, деятельность которых будет так или иначе затронута ее работой и результатами. "},{Вопросы:"Процесс создания программ",Ответы:"Процесс создания программ можно представить как последовательность действий:\nПостановка задачи - точная формулировка требований, предъявляемых к работе программы, с описанием входной и выходной информации, и, возможно, описание подходов к решению задачи\nАлгоритм - точный набор инструкций, описывающих однозначный порядок действий исполнителя (компьютера), от допустимых исходных данных для достижения результата решения задачи за конечное время.\nПрограммирование - теоретическая и практическая деятельность, связанная с созданием программ.\nИнформационная система (ИС) — система, предназначена для хранения, поиска и обработки информации, и соответствующие организационные ресурсы, которые обеспечивают и распространяют информацию."},{Вопросы:"Информационная система",Ответы:"Информационная система - взаимосвязанная совокупность средств, методов и персонала, используемых для хранения, обработки и выдачи информации в интересах достижения поставленной цели."},{Вопросы:"свойства программного обеспечения:",Ответы:'Следует выделить следующие свойства программного обеспечения: \n• Корректность\n• Устойчивость\n• Восстанавливаемость\n• Надежность\nКорректность программного обеспечения — свойство безошибочной реализации требуемого алгоритма при отсутствии таких мешающих факторов, как ошибки входных данных, ошибки операторов, сбои и отказы ЭВМ. Под корректностью понимаются свойства программы, свидетельствующие об отсутствии в ней ошибок, допущенных разработчиком на различных этапах проектирования (спецификации, проектирования алгоритма и структур данных, кодировании). Корректность самой программы понимают по отношению к целям, поставленным перед ее разработкой (это относительное свойство).\nУстойчивость — свойство осуществлять требуемое преобразование информации при сохранении выходных решений программы в пределах допусков, установленных спецификацией. Устойчивость характеризует поведение программы при воздействии на нее таких факторов неустойчивости, как ошибки операторов ЭВМ, а также не выявленные ошибки программы.\nВосстанавливаемость — свойство ПО, характеризующее возможность приспосабливаться к обнаружению ошибок и их устранению.\nНадежность можно представить совокупностью следующих характеристик:\n- целостностью программного средства (способностью его к защите от отказов);\n- живучестью (способностью к входному контролю данных и их проверки в ходе работы);\n- завершенностью (бездефектностью готового программного средства, характеристикой качества его тестирования);\n- работоспособностью (способностью программного средства к восстановлению своих возможностей после сбоев).\nОтличие понятия корректности и надежности программ состоит в следующем:\n- надежность характеризует как программу, так и ее "окружение" (качество аппаратуры, квалификацию пользователя и т. п.);\n- говоря о надежности программы, обычно допускают определенную, хотя и малую долю ошибок в ней и оценивают вероятность их появления.'},{Вопросы:"группы прогаммного обеспечения",Ответы:"В зависимости от условий распространения и использования можно выделить следующие группы ПО:\n· Собственническое (или проприетарное)\n· Свободное ПО\n· ПО с открытым кодом"},{Вопросы:"Направления в программировании(расписать)",Ответы:"Направления в программировании:\n1.        Разработка web-приложений. Ориентирована на разработку веб-приложений. Web-программирование можно разделить на backend (написание серверных скриптов – PHP, Python, Ruby) и frontend (разработка юзерского интерфейса – Javascript, HTML, CSS).\n2.        Разработка desktop-приложений. Разработка ПО для различных операционных систем. Все разнообразие софта, что мы используем в повседневности.\n3.        Разработка серверных приложений. Это различные игровые сервера, IM-сервисы (серверная часть Skype, ICQ, MSN), банковские БД.\n4.        Разработка мобильных приложений. Множество Java-приложений. VK, Viber, Яндекс.Карты, переводчики, электронные читалки.\n5.        Программирование встраиваемых систем. Отрасль программирования для различной домашней техники: пылесосы, холодильники, стиральные машины, плееры, навигаторы, электронные весы. Здесь задействованы научные разработки с использованием специализированных языков, типа MATLAB.\n6.        Системное программирование. Написание различных драйверов для оборудования, программирования «ядра» операционных систем (создание компиляторов и интерпретаторов для ЯП).\n7.        Разработка игр. Разработка игр для ПК, консолей и мобильный устройств.\n8.        Олимпиадное программирование и решение задач. Программирование на различных «непрактичных» и не распространенных языках для решения каких-то оригинальных задач\n9.        Программирование для бухгалтерских и финансовых продуктов «1С: Предприятие». Вся бухгалтерия в России завязана на этом продукте. Но недостаточно знать лишь сам язык, важно понимать основы бухгалтерского учета. \n10.      Программирование баз данных. Способность хранить миллиарды строк информации.\n11.       Science. Нейронные сети, моделирование структуры ДНК, запуск спутников, моделирование Большого Взрыва."},{Вопросы:"Основные классы инструментальных средств",Ответы:"Выделяют три основных класса инструментальных сред разработки и сопровождения ПС (программных средств):\n1. инструментальные среды программирования (предназначена в основном для поддержки процессов программирования (кодирования), тестирования и отладки ПС), \n2. рабочие места компьютерной технологии (ориентировано на поддержку ранних этапов разработки ПС (системного анализа и спецификаций) и автоматической генерации программ по спецификациям), \n3. инструментальные системы технологии программирования (предназначена для поддержки всех процессов разработки и сопровождения в течение всего жизненного цикла ПС и ориентирована на коллективную разработку больших программных систем с продолжительным жизненным циклом).",Column3:"Свойства пункта 1.: -может обладать специализированностью и интегрированности (интегрированные среды программирования - система программирования)\nСвойства пункта 2.: -специализированность\n-ориентированность на конкретную технологию программирования\n-как правило, интегрированность\n-комплексность\nСвойства пункта 3.: -комплексность\n-ориентированность на коллективную разработку\n-интегрированность\n-обладает технологической определенностью или получает это свойство в процессе расширения (настройки)"},{Вопросы:"Что такое API, для чего нужно, напишите примеры",Ответы:'API (Application programming interface) — контракт, который предоставляет программа. «Ко мне можно обращаться так и так, я обязуюсь делать то и это». Другими словами, API – представление (view) предоставляемого функционала. Специально разработана для запросов в определенный удаленный сервис.\nAPI определяет функциональность, которую предоставляет программа (модуль, библиотека), при этом API позволяет абстрагироваться от того, как именно эта функциональность реализована.\n\nПример API яндекс карт.\n<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml">\n<head>\n <title>Быстрый старт. Размещение интерактивной карты на \nстранице</title>\n <meta http-equiv="Content-Type" content="text/html; \ncharset=utf-8" />\n <script src="https://api-maps.yandex.ru/2.1/?apikey=ваш API-\nключ&lang=ru_RU" type="text/javascript">\n <\/script>\n <script type="text/javascript">\n ymaps.ready(init);\n function init(){\n var myMap = new ymaps.Map("map", {\n center: [55.76, 37.64],\n zoom: 7\n });\n }\n <\/script>\n</head>\n<body>\n <div id="map" style="width: 600px; height: 400px"></div>\n</body>\n</html>',Column3:'API государственной думы\nvar token = "10e644926dae6a63f3fb0a2f47b0e0ac0e544804";\n$.ajax({\n "url":"http://api.duma.gov.ru/api/" + token + "/search.json",\n "data": {\n "status":6,//законопроекты,рассмотрение которых завершено\n "registration_start": "2011-01-01",\n "registration_end":"2011-03-31",\n "limit": 10//вывести первые 10 найденных законопроектов\n },\n "dataType": "jsonp",\n "success": function(data) {\n // возникла ошибка, выводим код и сообщение об ошибке\n if (data.code) {\n $(".ajax").remove();\n alert("Error #" + data.code + ": " + data.text);\n return false;\n }\n // отправляем данные в шаблон и получаем конечный html\n var resultHtml = tmpl("column1_tmpl", { data: data });\n // выводим на странице результат\n $("#column-1 .ajax").replaceWith(resultHtml);\n }\n});\r'},{Вопросы:"Что такое Java IO",Ответы:"IO API (Input & Output) – Java API, которые облегчают работу с потоками. В java.io существуют так называемые потоки ввода и вывода (InputStream and OutputStream). В основном java.io предназначен для чтения и записи данных в ресурс, файл, при работе с сетевым подключением, System.err, System.in, System.out или при работе с буфером.",Column3:"у Java IO есть свои недостатки:\n1. Блокирующий доступ для ввода/вывода данных. Проблема состоит в том, что когда разработчик пытается прочитать файл или записать что-то в него, используя Java\nIO, он блокирует файл и доступ к нему до момента окончания выполнения своей задачи.\n2. Отсутствует поддержка виртуальных файловых систем.\n3. Нет поддержки ссылок.\n4. Очень большое количество checked исключений."},{Вопросы:"Что такое Java NIO",Ответы:"Java.nio (Non-blocking I/O) - набор API-интерфейсов языка программирования Java, которые предлагают функции для интенсивных операций ввода-вывода. Он был представлен с выпуском Java J2SE 1.4 компанией Sun Microsystems в дополнение к существующему стандарту ввода-вывода.",Column3:"Java NIO — это библиотека, представленная в Java 1.4. Java NIO с момента своего\nзапуска предоставила альтернативный способ обработки операций ввода-вывода и\nсетевых транзакций. Он считается альтернативой библиотекам Java Networking и Java\nIO. Java NIO была разработана с целью сделать транзакции для ввода и вывода\nасинхронными и неблокирующими.",Column4:"Java NIO существенно повышает эффективность работы с файлами за счет использования\nвнутри блоков. Еще один плюс состоит в том, что библиотека NIO разбита на две части:\nодна для работы с файлами, вторая — для работы в сети."},{Вопросы:"Пример кода Java NIO, Java IO. Кто быстрее.",Ответы:'//Java IO\npublic static void main(String[] args) {\n long currentMills = System.currentTimeMillis();\n long startMills = currentMills;\n File src = new File("/Users/IdeaProjects/testFolder/text.txt");\n File dst = new File("/Users/IdeaProjects/testFolder/text1.txt");\n copyFileByIO(src, dst);\n currentMills = System.currentTimeMillis();\n System.out.println("Время выполнения в миллисекундах: " + (currentMills - startMills));\n }\n public static void copyFileByIO(File src, File dst){\n try(InputStream inputStream = new FileInputStream(src);\n OutputStream outputStream = new FileOutputStream(dst)){\n byte[] buffer = new byte[1024];\n int length;\n // Читаем данные в байтовый массив, а затем выводим в OutStream\n while((length = inputStream.read(buffer)) > 0){\n outputStream.write(buffer, 0, length);\n }\n } catch (IOException e) {\n e.printStackTrace();\n }\n }\n',Column3:'// Java NIO\npublic static void main(String[] args) {\n long currentMills = System.currentTimeMillis();\n long startMills = currentMills;\n File src = new File("/Users/IdeaProjects/testFolder/text.txt");\n File dst = new File("/Users/IdeaProjects/testFolder/text2.txt");\n copyFileByChannel(src, dst);  // копия nio\n currentMills = System.currentTimeMillis();\n System.out.println("Время выполнения в миллисекундах: " + (currentMills - startMills));\n }\n public static void copyFileByChannel(File src, File dst){\n // 1. Получаем FileChannel исходного файла и целевого файла\n try(FileChannel srcFileChannel = new FileInputStream(src).getChannel();\n FileChannel dstFileChannel = new FileOutputStream(dst).getChannel()){\n // 2. Размер текущего FileChannel\n long count = srcFileChannel.size();\n while(count > 0){ \n/**=========================================\n * 3. Записать байты из FileChannel исходного файла в целевой FileChannel\n * 1. srcFileChannel.position (): начальная позиция в исходном файле не может\nбыть отрицательной\n * 2. count: максимальное количество переданных байтов, не может быть\nотрицательным\n * 3. dstFileChannel: целевой файл \n*=========================================*/\n long transferred = srcFileChannel.transferTo(srcFileChannel.position(),\n count, dstFileChannel);\n // 4. После завершения переноса измените положение исходного файла на новое\nместо\n srcFileChannel.position(srcFileChannel.position() + transferred);\n // 5. Рассчитаем, сколько байтов осталось перенести\n count -= transferred;\n }\n } catch (FileNotFoundException e) {\n e.printStackTrace();\n } catch (IOException e) {\n e.printStackTrace();\n }\n }',Column4:"Результаты зависит от размера файла\n\nНет особого смысла сравнивать производительность между ними, так как они служат разным целям. NIO представляет собой более абстрактный низкоуровневый ввод-вывод данных, а NIO2 ориентирован на управление файлами. "},{Вопросы:"отличия между Java IO и Java NIO",Ответы:"IO: Потокоориентированный, Блокирующий (синхронный) ввод/вывод, Он имеет дело с данными в потоке\nNIO: Буфер-ориентированный, Неблокирующий (асинхронный) ввод/вывод, Селекторы, Доступны каналы, Он имеет дело с данными в блоках"},{Вопросы:"Потокоориентированный ввод/вывод",Ответы:"Потокоориентированный ввод/вывод подразумевает чтение/запись из потока/в поток одного или нескольких байт в единицу времени поочередно. \nДанная информация нигде не кэшируются. Таким образом, невозможно произвольно двигаться по потоку данных вперед или назад. \nЕсли надо произвести подобные манипуляции, придется сначала кэшировать данные в буфере."},{Вопросы:"буфер-ориентированный ввод/вывод",Ответы:"Данные считываются в буфер, который обрабатываются позже, и при необходимости могут перемещаться туда и обратно в буфере."},{Вопросы:"Блокирующий и неблокирующий ввод/вывод",Ответы:"Потоки ввода/вывода (streams) в Java IO являются блокирующими. Когда в потоке выполнения вызывается read() или write() любого класса из пакета java.io.*, происходит блокировка до тех пор, пока данные не будут считаны или записаны. Поток выполнения в данный момент не может делать ничего другого.\nНеблокирующий режим Java NIO позволяет запрашивать считанные данные из канала и получать только то, что доступно на данный момент, или вообще ничего, если доступных данных пока нет. Вместо того, чтобы оставаться заблокированным пока данные не станут доступными для считывания, поток выполнения может заняться чем-то другим."},{Вопросы:"API обращений к классам ввода/вывода",Ответы:"В Java API обращений зависит от выбранного типа режима (Java NIO или Java IO). API в Java IO - блокирующие потоки InputStream. В то время как в Java NIO это буферы."},{Вопросы:"Java NIO Buffer, что это, для чего нужно, пример",Ответы:"Буфер, по сути, является средой для хранения данных, пока поток не прочитает данные из него и не запросит новые данные. \nОсновным шагом к чтению данных из источника ввода является чтение данных в буфер, фиксированная часть памяти, используемая для хранения этих данных перед их чтением в канал. Буфер обеспечивает предварительную загрузку данных определенного размера для ускорения чтения файлов, входных данных и потоков данных. Размер буфера настраивается в блоках от 2 до степени n.",Column3:"ByteBuffer buf = ByteBuffer.allocate (2048);\nint bytesRead = channel.read(buf);\nbuf.flip(); // меняем режим на чтение\nwhile (buf.hasRemaining()) {\nbyte data = buf.get(); // есть методы для примитивов\n}\nbuf.clear(); // очистили и можно переиспользовать"},{Вопросы:"типы Java NIO Buffer которые могут использоваться в зависимости от типа ввода",Ответы:"Различные типы буферов, которые могут использоваться в зависимости от типа ввода:\nByteBuffer: используется для чтения потоков символов или файлов в байтовом\nвыражении\n CharBuffer: используется для чтения символов в полном наборе ASCII\n DoubleBuffer: используется специально для двойных значений данных, таких как\nпоказания датчиков\n FloatBuffer: используется для чтения постоянных потоков данных для таких целей, как\nаналитика\n LongBuffer: используется для чтения значений типа данных long\n IntBuffer: используется для чтения целочисленных значений для результатов или\nрезультатов.\n ShortBuffer: используется для чтения коротких целочисленных значений\nКаждый буфер предназначен для его конкретного использования. Буферы, обычно\nиспользуемые для файлов, являются ByteBuffer и CharBuffer."},{Вопросы:"Канальные передачи",Ответы:"Передача канала представляет собой процесс передачи данных из одного канала в другой. Передача канала может осуществляться из определенной позиции буфера канала. Однако при значении позиции, равном нулю, можно копировать или реплицировать полный источник ввода в указанное место назначения вывода. Например, установление канала между ключевым словом и текстовым редактором позволит непрерывно переносить ввод с клавиатуры в текстовый редактор. Чтобы облегчить передачу канала, Java NIO оснащен двумя функциями, а именно — transferFrom() и transferTo() ."},{Вопросы:"Java NIO Channel",Ответы:"Каналы являются основной средой для неблокирующего ввода-вывода. Каналы аналогичны потокам, доступным для блокировки ввода-вывода. Эти каналы поддерживают данные по сетям, а также файлы ввода-вывода данных. Каналы читают данные из буферов по мере необходимости. Буферы хранят данные до тех пор, пока они не будут прочитаны.\nКаналы имеют несколько реализаций в зависимости от данных, которые нужно прочитать. В отличие от потоков, которые используются в Java IO, NIO Channel является двусторонним, то есть может и считывать, и записывать. Канал Java NIO поддерживает асинхронный поток данных как в режиме блокировки, так и в режиме без блокировки."},{Вопросы:"Что такое Direct буфер, для чего он нужен, пример",Ответы:"Java NIO поддерживает тип ByteBuffer, обычно известный как direct (прямой) буфер.\n\nDirect буфер по существу могут использоваться как любой другой ByteBuffer (и реализованы как подкласс ByteBuffer), но имеют свойство - их базовая память выделяется вне кучи Java. В частности, Direct буферы обладают следующими свойствами:\n• после выделения их адрес памяти фиксируется на время жизни буфера;\n• поскольку их адрес фиксирован, ядро ​​может безопасно обращаться к ним напрямую, и, следовательно, прямые буферы могут использоваться более эффективно в операциях ввода-вывода;\n• в некоторых случаях доступ к ним из Java может быть более эффективным (потенциально меньше накладных расходов при поиске адреса памяти и/или других служебных операций, необходимых перед доступом к объекту Java);\n• через Java Native Interface вы можете фактически установить адрес произвольно, если это необходимо (например, для доступа к оборудованию по определенному адресу или для самостоятельного выполнения выделения)."},{Вопросы:"Что такое MappedFileBuffer, для чего он нужен, пример",Ответы:'Оболочка для файлов в памяти, которая сохраняет семантику ByteBuffer, но поддерживает файлы размером больше 2 ГБ. В отличии от обычных байтовых буферов, весь доступ осуществляется через абсолютный индекс, а индексы представляют собой длинные значения.\n\nЭто достигается с помощью набора перекрывающихся буферов, основанных на "размере сегмента", переданном во время построения. Размер сегмента - самый большой непрерывный суббуффер, к которому можно получить доступ через getBytes(long, int), и putBytes(long, byte[]), и он может быть не больше 1 ГБ.',Column3:'CharBuffer charBuffer = CharBuffer.wrap("Запись в файл");\nPath pathToWrite = getFileURIFromResources("fileToWriteTo.txt");\ntry (FileChannel fileChannel = (FileChannel) Files\n .newByteChannel(pathToWrite, EnumSet.of(\n StandardOpenOption.READ, \n StandardOpenOption.WRITE, \n StandardOpenOption.TRUNCATE_EXISTING))) {\n MappedByteBuffer mappedByteBuffer = fileChannel\n .map(FileChannel.MapMode.READ_WRITE, 0, charBuffer.length());\n if (mappedByteBuffer != null) {\n mappedByteBuffer.put(\n Charset.forName("utf-8").encode(charBuffer));\n }\n}',Column4:"Чтобы создать MappedByteBuffer из файла, сначала нужно создать FileChannel из него. \nПосле того, как канал создан, можно вызвать метод map() на нем, передавая в режиме Map, позицию, с которой хотим читать, и параметр size , который указывает, сколько байтов необходимо.\n\nКак только сопоставили файл с буфером памяти, можно прочитать данные из него в буфер Char. Содержимое файла, которое читаем при вызове метода decode(),передающего MappedByteBuffer, чтение происходит из памяти, а не с диска. Поэтому это чтение будет очень быстрым"},{Вопросы:"Что такое Java NIO Selector, для чего он нужен, пример",Ответы:"Селектор Java NIO – компонент, который может проверять один или несколько экземпляров Java NIO Channel и определять, какие каналы готовы, например, для чтения или записи. Таким образом, один поток может управлять несколькими каналами и, следовательно, несколькими сетевыми подключениями.",Column3:"Selector selector = Selector.open();\nSocketChannel channel = SocketChannel.open();\nchannel.configureBlocking(false); // неблокирующий режим\nSelectionKey key = channel.register(selector, SelectionKey.OP_READ);"},{Вопросы:"Java NIO – FileLock, для чего нужно, пример",Ответы:"Используется для обеспечения блокировки всего файла или его части, чтобы файл или его часть не были доступны для общего доступа, чтобы обеспечить или применить такую ​​блокировку, мы должны использовать FileChannel или AsynchronousFileChannel, который предоставляет для этой цели два метода lock() и tryLock(). Предоставляемая блокировка может быть двух типов: \n- Эксклюзивная блокировка – не позволяет другим программам получать перекрывающуюся блокировку любого типа.\n- Общая блокировка не позволяет другим одновременно работающим программам получать перекрывающуюся эксклюзивную блокировку, но позволяет им получать перекрывающиеся общие блокировки.",Column3:'FileChannel fileChannel = FileChannel.open(path, StandardOpenOption.READ);\nFileLock lock = fileChannel.lock(0, Long.MAX_VALUE, true);\nSystem.out.println("Lock acquired: " + lock.isValid());\nSystem.out.println("Lock is shared: " + lock.isShared());'},{Вопросы:"Архитектура сервера Netty",Ответы:"Сервер Netty - сервер NIO. Общая архитектура Netty может выглядеть следующим образом - существует 3 обработчика: \n - Connection handler — обработчик который отвечает за подключения/отключения клиентов. Здесь будет происходить проверка возможности подключения клиентов (черные, белые списки, IP фильтры и т.д.), а так же корректное отключение клиентов с закрытием всех используемых ресурсов. \n - Frame handler — обработчик разделяющий поток данных на отдельные пакеты. Для удобства работы примем, что пакет состоит из двух частей. 1-заголовок, в котором описана длинна пакета, и 2-непосредственно данные пакета.\n - Packet handler — обработчик игровых сообщений. Здесь мы будем получать данные из пакета и дальше их обрабатывать."},{Вопросы:"Что такое реактивность?пример",Ответы:"Реактивное программирование — асинхронность, соединенная с потоковой обработкой данных. Если в асинхронной обработке нет блокировок потоков, но данные обрабатываются все равно порциями, то реактивность добавляет возможность обрабатывать данные потоком.\n\nПример: когда начальник поручает задачу Васе, тот должен передать результат Диме, а Дима вернуть начальнику? Но задача — это некая порция, и пока она не будет сделана, дальше передать ее нельзя. Такой подход действительно разгружает начальника, но Дима и Вася периодически простаивают, ведь Диме надо дождаться результатов работы Васи, а Васе — дождаться нового задания.\n\nИдея реактивности построена на паттерне проектирования Observer. Есть подписчики и то, на что подписываемся. Пример: рассмотрен Твиттер, подписаться на какое-то сообщество или человека, а потом получать обновления можно в любой соцсети. После подписки, как только появляется новое сообщение, всем подписчикам приходит notify, то есть уведомление. Это базовый паттерн.\n\nВ данной схеме есть:\n- Publisher — тот, кто публикует новые сообщения;\n- Observer — тот, кто на них подписан. В реактивных потоках подписчик обычно называется Subscriber",Column3:"Есть датчик дыма и градусник. Когда дыма становится много и/или температура растет, на соответствующих датчиках увеличивается значение. Когда значение и температура на датчике дыма оказываются выше пороговых, включается колокольчик и оповещает о тревоге.\n\nЕсли был традиционный, а не реактивный подход, мы бы писали код, который каждые пять минут опрашивает детектор дыма и датчик температуры, и включает или выключает колокольчик. Однако в реактивном подходе это делает реактивный фреймворк, а мы только прописываем условия: колокольчик активен, когда детектор больше X, а температура больше Y. Это происходит каждый раз, когда приходит новое событие.\n\nДетектор дыма и термометр — это публикаторы сообщений, источники данных (Publisher), а колокольчик на них подписан, то есть он Subscriber, или наблюдатель (Observer)\n- оператор distinctUntilChanged. Он убирает одинаковые значения, идущие друг за другом\n- оператор throttle. Если два события (например два клика) произошли в течение 250 мс, их нужно сгруппировать.\n",Column4:'Observable<Integer> observableCO2 = Observable.create(sensorCO2);\n\t\tObservable<Integer> observableTemperature = Observable.create(sensorTemperature);\n\n\t\tobservableCO2.join(\n\t\t\tobservableTemperature,\n\t\t\ti -> Observable.timer(100, TimeUnit.MILLISECONDS),\n\t\t\ti -> Observable.timer(100, TimeUnit.MILLISECONDS),\n\t\t\t(co2, temperature) -> new DataSensor(temperature, co2)\n\t\t).subscribe(new Observer<>() {\n\t\t\t@Override\n\t\t\tpublic void onSubscribe(@NonNull Disposable d) {\n\t\t\t\tSystem.out.println("onSubscribe");\n\t\t\t}\n\n\t\t\t@Override\n\t\t\tpublic void onNext(@NonNull DataSensor dataSensor) {\n\t\t\t\tint temperature = dataSensor.getTemperature();\n\t\t\t\tint co2 = dataSensor.getCo2();\n\n\t\t\t\tString warningMessage = "";\n\n\t\t\t\tif (temperature > NORM_TEMP && co2 > NORM_CO2) {\n\t\t\t\t\twarningMessage = "\\nALARM!!!";\n\t\t\t\t} else if (temperature > NORM_TEMP) {\n\t\t\t\t\twarningMessage = "\\nWarning! temp";\n\t\t\t\t} else if (co2 > NORM_CO2) {\n\t\t\t\t\twarningMessage = "\\nWarning! CO2";\n\t\t\t\t}\n\t\t\t\tSystem.out.println("Temperature: " + temperature + ", CO2: " + co2 + " " + warningMessage);\n\t\t\t}'},{Вопросы:"RxJava, кто такой Observable и Observer",Ответы:'Observable - представляет наблюдаемый объект или "данные" в парадигме представления модели. Он может быть подклассом для представления объекта, который приложение хочет видеть.\n\nУ наблюдаемого объекта может быть один или несколько наблюдателей. Наблюдателем может быть любой объект, реализующий интерфейс Observer. После изменения экземпляра observable приложение, вызывающее метод notifyObservers Observable, уведомляет всех своих наблюдателей об изменении вызовом их метода обновления.\n\nObserver - предоставляет механизм для получения на основе push-уведомлений. После того, как Наблюдатель вызывает метод subscribe наблюдаемого объекта, наблюдаемый объект вызывает метод onNext(T) наблюдателя для предоставления уведомлений. Наблюдаемый объект с хорошим поведением вызовет метод OnCompleted() наблюдателя ровно один раз или onError наблюдателя (java.lang.throwable) метод ровно один раз.'},{Вопросы:"Для чего нужен ReplaySubject, пример",Ответы:"ReplaySubject имеет специальную возможность кэшировать все поступившие в него данные. Когда у него появляется новый подписчик, последовательность выдана ему, начиная с начала. Все последующие поступившие данные будут выдаваться подписчикам как обычно.\n\nКэшировать всё подряд не всегда лучшая идея, так как последовательности могут быть длинными или даже бесконечными. Фабричный метод ReplaySubject.createWithSize ограничивает размер буфера, а ReplaySubject.createWithTime время, которое объекты будут оставаться в кеше.\nСоздание ReplaySubject с ограничением по времени требует объект планировщика (Scheduler), который является представлением времени в Rx. ReplaySubject.createWithTimeAndSize ограничивает буфер по обоим параметрам.\n\nпро replaysubject еще есть в ячейке 47"},{Вопросы:"Для чего нужен BehaviorSubject, пример",Ответы:"Субъект, который отправляет самый последний элемент, который он наблюдал, и все последующие наблюдаемые элементы каждому подписанному наблюдателю (Observer). BehaviorSubject is an Observable\n\nBehaviorSubject хранит только последнее значение. Это то же самое, что и ReplaySubject, но с буфером размером 1. Во время создания ему может быть присвоено начальное значение, таким образом гарантируя, что данные всегда будут доступны новым подписчикам. Начальное значение предоставляется для того, чтобы быть доступным еще до поступления данных. Так как роль BehaviorSubject – всегда иметь доступные данные, считается неправильным создавать его без начального значения, также как и завершать его.",Column3:'BehaviorSubject<Integer> s = BehaviorSubject.create();\ns.onNext(0);\ns.onNext(1);\ns.onNext(2);\ns.subscribe(v -> System.out.println("Late: " + v)); \ns.onNext(3);\n\nВывод\nLate: 2\nLate: 3'},{Вопросы:"Для чего нужен AsyncSubject, пример",Ответы:"Subject’ы являются расширением Observable, одновременно реализуя интерфейс Observer. Они могут принимать сообщения о событиях (как observer) и сообщать о них своим подписчикам (как observable).\n \n AsyncSubject также хранит последнее значение. Разница в том, что он не выдает данных до тех пока не завершится последовательность. Его используют, когда нужно выдать единое значение и тут же завершиться.\n \n AsyncSubject<Integer> s = AsyncSubject.create();\n s.subscribe(v -> System.out.println(v));\n s.onNext(0);\n s.onNext(1);\n s.onNext(2);\n s.onCompleted();\n \n Вывод:\n \n 2\n \n Обратите внимание, что если бы мы не вызвали s.onCompleted(), этот код ничего бы не напечатал."},{Вопросы:"Реактивные потоки в Java 9, для чего нужны, пример",Ответы:"Реактивные потоки – это стандартный способ асинхронной обработки данных в потоковом стиле. Используются для создания потоковых компонентов в различных приложениях. В Java 9 нет реализации реактивных потоков, они используются только как спецификация, но существует библиотека, реализующая реактивный подход - RxJava. С помощью нее мы подписываемся на поток данных, и определяем несколько обработчиков, то есть методы, которые будут запущены в начале обработки потока. ДА Я ХУЙ ЗНАЕТ КАКОЙ ТУТ КОД ПИСАТЬ ТАМ В ДЖАВА 9 ДАЖЕ РЕАЛИЗАЦИИ НЕТ КАКОЙ КОД АААААААА"},{Вопросы:"Модели реактивных потоков в Java 9",Ответы:"Существует две модели потоков:\n - Push-модель — когда идет «проталкивание» значений.\n Например, подписались на кого-то в Telegram или Instagram и получаете оповещения (они\n так и называются — push-сообщения, их не надо запрашиваеть, они приходят сами). Это\n может быть, например, всплывающее сообщение. Можно определить, как реагировать на\n каждое новое сообщение.\n - Pull-модель — когда мы сами делаем запрос.\n Например, мы не хотим подписываться, т.к. информации и так слишком много, а хотим\n сами заходить на сайт и узнавать новости.\n Для Push-модели определяем callbacks, то есть функции, которые будут вызваны, когда\n придет очередное сообщение, а для Pull-модели можно воспользоваться методом request,\n когда мы захотим узнать, что новенького"},{Вопросы:"Что такое Filter operator,Map operator, Delay operator для чего нужны, примеры",Ответы:"Filter По синтаксису этот фильтр точно такой же, как обычный. Но если в стриме Java 8 все данные есть сразу, здесь они могут появляться постепенно. Стрелки вправо — это временная шкала, а в кружочках находятся появляющиеся данные. Мы видим, что фильтр оставляет в итоговом потоке только значения, превышающие 10.\nMap Это действие, происходящее с каждым значением. Здесь — умножить на десять: было 3, стало 30; было 2, стало 20 и т.д.\nDelay Задержка: все операции сдвигаются. Этот оператор может понадобиться, когда значения уже генерируются, но подготовительные процессы еще происходят, поэтому приходится отложить обработку данных из потока."},{Вопросы:"Что такое Reduce operator,Scan operator, Merge operator для чего нужны, примеры",Ответы:"Reduce Он дожидается конца работы потока (onComplete) — на схеме она представлена вертикальной чертой. После чего получаем результат — здесь это число 15. Оператор reduce сложил все значения, которые были в потоке. \nScan Оператор scan рассчитывает текущее значение нарастающим итогом: сначала был 1, потом прибавил к предыдущему значению 2, стало 3, потом прибавил 3, стало 6, еще 4, стало 10 и т.д. На выходе получили 15. Дальше мы видим вертикальную черту — onComplete. Но, может быть, его никогда не произойдет: некоторые потоки не завершаются. Например, у термометра или датчика дыма нет завершения, но scan поможет рассчитать текущее суммарное значение, а при некоторой комбинации операторов — текущее среднее значение всех данных в потоке.\nMerge Объединяет значения двух потоков."},{Вопросы:"Что такое FlatMap operator,Buffer operator, для чего нужны, примеры",Ответы:"FlatMap часто используется при обработке потока данных, полученных с сервера. Т.к. сервер возвращает поток, чтобы мы смогли обрабатывать отдельные данные, этот поток сначала надо «развернуть». Это и делает flatMap. \nBuffer Это оператор, который помогает группировать данные. На выходе Buffer получается поток, элементами которого являются списки (List в Java). Он может пригодиться, когда мы хотим отправлять данные не по одному, а порциями."},{Вопросы:"Что такое side effects, методы. Примеры",Ответы:"Методы побочных эффектов не влияют на поток сам по себе. Вместо этого они вызываются, когда происходят определенные события, чтобы позволить реагировать на эти события. Например: если заинтересованы в том, чтобы делать что-то вне ваших Subscriber обратных вызовов при возникновении какой-либо ошибки, вы должны использовать doOnError() метод и передавать ему функциональный интерфейс, который будет использоваться при возникновении ошибки ",Column4:"someObservable\n .doOnError(new Action1() {\n @Override\n public void call(Throwable t) {\n // use this callback to clean up resources,\n // log the event or or report the\n // problem to the user\n }\n })"},{Вопросы:"Обаботчики ошибок в RxJava",Ответы:"В роли базового обработчика ошибок в RxJava используется RxJavaPlugins.onError. Он обрабатывает все ошибки, которые не удается доставить до подписчика. По умолчанию все ошибки отправляются именно в него, поэтому могут возникать критические сбои приложения.\nЕсли у RxJava нет базового обработчика ошибок, подобные ошибки будут скрыты, и разработчики будут находится в неведении о потенциальных проблемах в коде.\nНачиная с версии 2.0.6, RxJavaPlugins.onError разделяет ошибки библиотеки/реализации и ситуации, когда ошибку доставить невозможно. Ошибки, отнесенные к категории «багов» вызываются как есть, остальные же оборачиваются в UndeliverableException и после вызываются.\nОдна из основных ошибок, с которыми сталкиваются в RxJava — OnErrorNotImplementedException. Эта ошибка возникает, если observable вызывает ошибку, а в подписчике не реализован метод onError. Это пример ошибки, которая для базового обработчика ошибок RxJava является «багом» и не оборачивается в UndeliverableException.\nUndeliverableException возникает, если нет активного подписчика, которому может быть доставлена ошибка.\nОбрабатываем ошибки\nПервый шаг — посмотреть на возникающие ошибки и попытаться определить, что их вызывает. Идеально, если удастся исправить проблему у её источника, чтобы предотвратить передачу ошибки в RxJavaPlugins.onError.\nРешение для примера с zipWith — взять один или оба источника и реализовать в них один из методов для перехвата ошибок. Например, можно использовать onErrorReturn для передачи вместо ошибки значения по умолчанию. Пример с ConnectableObservable исправить проще — просто надо убедиться в отсоединении Observable в момент, когда последний подписчик отписывается. autoConnect(), к примеру, имеет перегруженную\nреализацию, которая принимает функцию, отлавливающую момент соединения. Другой путь решения проблемы — подменить базовый обработчик ошибок своим собственным. Метод RxJavaPlugins.setErrorHandler(Consumer<Throwable>) поможет в этом. Если это подходящее решение, можно перехватывать все ошибки, отправленные в RxJavaPlugins.onError, и обрабатывать их по своему усмотрению. Но оно может оказаться довольно сложным. Если вручную создаются Observable, то можно вместо emitter.onError() вызывать emitter.tryOnError(). Этот метод передает ошибку, только если поток не уничтожен и имеет подписчиков."},{Вопросы:"Горячие и холодные потоки в RxJava, что они делают",Ответы:"Cold Observable:\n• Не рассылает объекты, пока на него не подписался хотя бы один подписчик;\n• Если observable имеет несколько подписчиков, то он будет рассылать всю последовательность объектов каждому подписчику.\nПример cold observable – методы ретрофит-интерфейса. Каждый раз когда вызывается метод subscribe(), выполняется соответствующий запрос на бэкенд и подписчик получает объект-респонс.\nHot Observable:\n• Рассылает объекты, когда они появляются, независимо от того есть ли подписчики;\n• Каждый новый подписчик получает только новые объекты, а не всю последовательность.\nCold Observables могут воспроизводить свои Наблюдения для каждого Наблюдателя, гарантируя, что все Наблюдатели получают все данные. Большинство управляемых данными Observables холодные, включая фабрики Observable.just () и Observable.fromIterable ().\nПример: у нас есть два наблюдателя, подписанных на Observable. Observable сначала испускает все выбросы первому Observer, а затем вызывает onComplete (). Затем он снова отправляет все выбросы второму Обозревателю и затем вызывает onComplete (). Через два отдельных потока они оба получают одинаковые данные.\nHot Observable передает одинаковые выбросы всем наблюдателям. Если наблюдатель подписывается на hot Observable, получает те же выбросы, а затем приходит к другому наблюдателю, второй наблюдатель пропустит эти выбросы. hot Observables обычно представляют события, а не ограниченные наборы данных. События могут нести данные, но они являются чувствительными ко времени компонентами, и более поздние наблюдатели будут пропускать предыдущие данные. Например, событие пользовательского интерфейса JavaFX или Android может быть представлено как Hot Observable. В JavaFX можно использовать метод selectedProperty() объекта ToggleButton Добавить наблюдателя. Затем надо преобразовать логическое излучение в строку, указывающую состояние кнопки (ВВЕРХ или ВНИЗ)."},{Вопросы:"Освобождение потоков",Ответы:'Disposable Является связующим звеном между Observable и active Observer, вызов его dispose()метода останавливает выбросы и удаляет все ресурсы, используемые для этого Observer:\n fun main() {\n  val seconds = Observable.interval(1, TimeUnit.SECONDS)\n  val disposable = seconds.subscribe { println("Received: $it") }\n  TimeUnit.SECONDS.sleep(5)\n  // Dispose and stop emissions.\n  disposable.dispose()\n  // Sleep 5 secs: no new emissions.\n  TimeUnit.SECONDS.sleep(5)\n }\n Received: 0\n Received: 1\n Received: 2\n Received: 3\n Received: 4\nТакже Disposable применяется и в наблюдателе для самоутилизации. Observer получает свое собственное при подписке в качестве Disposable аргумента onSubscribe(d: Disposable).\n\nДля управления и удаления нескольких подписок применяется CompositeDisposable.\nУдаление с помощью Observable.create() - В случае вызова Observable.create() и результат возврата long-running или infinite Observable , функция isDisposed() должна регулярно проверять, продолжать ли отправлять запросы'},{Вопросы:"Реактивные операторы, какие бывают, примеры",Ответы:"Создание наблюдаемых Операторы, которые создают новые Observables. \n · Create— создать Observable с нуля, программно вызывая методы наблюдателя \n · Defer— не создавать Observable, пока наблюдатель не подпишется, и создавать новый Observable для каждого наблюдателя \n · Empty// Never—Throw создаем Observable с очень точным и ограниченным поведением \n · From— преобразовать какой-либо другой объект или структуру данных в Observable \n · Interval— создать Observable, который выдает последовательность целых чисел, разделенных определенным интервалом времени \n · Just— конвертировать объект или набор объектов в Observable, который излучает те или иные объекты \n · Range— создать Observable, который выдает диапазон последовательных целых чисел \n · Repeat- создать Observable, который многократно испускает определенный элемент или последовательность элементов \n · Start— создать Observable, который выдает возвращаемое значение функции \n · Timer— создать Observable, который испускает один элемент после заданной задержки\n \n Преобразование наблюдаемых\n Операторы, преобразующие элементы, испускаемые Observable.\n · Buffer— периодически собирать элементы из Observable в пакеты и выпускать эти пакеты,\n а не выпускать элементы по одному\n · FlatMap— преобразовать элементы, испускаемые Observable, в Observable, а затем свести\n выбросы из них в один Observable.\n · GroupBy- разделить Observable на набор Observable, каждый из которых испускает другую\n группу элементов из исходного Observable, организованную по ключу\n · Map- преобразовать элементы, испускаемые Observable, применяя функцию к каждому\n элементу\n · Scan— применить функцию к каждому элементу, испускаемому Observable,\n последовательно, и испускать каждое последующее значение\n · Window— периодически подразделять элементы из Observable на окна Observable и\n создавать эти окна, а не создавать элементы по одному\n Фильтрация наблюдаемых\n Операторы, которые выборочно испускают элементы из исходного Observable.\n · Debounce— испускать элемент из Observable только в том случае, если в течение\n определенного промежутка времени он не излучал другой элемент\n · Distinct— подавлять повторяющиеся элементы, испускаемые Observable\n · ElementAt— испускать только элемент n , испускаемый Observable\n · Filter— испускать только те элементы из Observable, которые проходят предикатную\n проверку\n · First— испускать только первый элемент или первый элемент, отвечающий условию, из\n Observable\n · IgnoreElements— не испускать никаких элементов из Observable, но отражать его\n уведомление о прекращении\n · Last— испускать только последний элемент, испускаемый Observable\n · Sample— испускать самый последний элемент, испускаемый Observable в течение\n периодических интервалов времени\n · Skip— подавить первые n элементов, испускаемых Observable\n · SkipLast— подавить последние n элементов, испускаемых Observable\n · Take— испускать только первые n элементов, испускаемых Observable\n · TakeLast— испускать только последние n элементов, испускаемых Observable\n \n Объединение наблюдаемых\n Операторы, которые работают с несколькими исходными Observable для создания одного\n Observable\n · And// Then—When объединить наборы элементов, испускаемых двумя или более\n Observable с помощьюPatternиPlanпосредников\n · CombineLatest— когда элемент испускается одним из двух Observable, объединяйте\n последний элемент, испускаемый каждым Observable с помощью указанной функции, и\n испускайте элементы на основе результатов этой функции.\n · Join- объединять элементы, испускаемые двумя наблюдаемыми, всякий раз, когда\n элемент из одного наблюдаемого испускается в течение временного окна, определенного\n в соответствии с элементом, испускаемым другим наблюдаемым\n · Merge— объединить несколько Observables в один, объединив их выбросы\n · StartWith— испускать указанную последовательность элементов, прежде чем начать\n испускать элементы из исходного Observable\n · Switch- преобразовать Observable, который испускает Observables, в один Observable,\n который испускает элементы, испускаемые самым последним из этих Observables\n · Zip- объединять выбросы нескольких Observable вместе с помощью указанной функции и\n испускать отдельные элементы для каждой комбинации на основе результатов этой\n функции."},{Вопросы:"Дерево решений наблюдаемых операторов\nэто треш",Ответы:"Это дерево может помочь найти нужный оператор ReactiveX Observable.\nя хочу создать НОВЫЕ OBSERVABLE:\n-Just - Наблюдаемый, который испускает определенный элемент\n-Start - Наблюдаемый, который был возвращен из функции,вызванной в абонентское время.\n-From - Наблюдаемый, который был возвращен из Action, Callable, Runnable или чего-то в этом роде, вызванного\nво время подписки\n-Timer - Наблюдаемый, который испускает определенный элемент после заданной задержки.\n-From - Наблюдаемый, который извлекает свои выбросы из определенного Array , Iterable или чего-то в этом роде\n-Start - извлекая его из будущего (Наблюдаемое,которое излучает возвращаемое значение функциональной директивы)\n-From - Наблюдаемый, который получает свою последовательность из будущего\n-Repeat - Наблюдаемый,который многократно испускает последовательность элементов\n-Create - Наблюдаемый с нуля,с индивидуальной логикой\nдля каждого наблюдателя,который подписался\n-Defer - Оператор defer ждет,пока наблюдатель не подпишется на него,а затем генерирует Наблюдаемый, обычно с заводской функцией Наблюдаемый\n-Range - Наблюдаемый,который испускает определенный элемент несколько раз.\nв определённые промежутки времени\n-Interval - Наблюдаемый,который испускает последовательность целых чисел,разделенных на заданный интервал времени.\n-Empty - Наблюдаемый,который не испускает никаких элементов,но заканчивается нормально.\nкоторый ничего не делает\n-Never - Наблюдательный,который не испускает никаких предметов и не прекращает работу.",Column3:'я хочу создать НОВЫЕ OBSERVABLE, объединив другие Observable:\n-Merge - объединив их выбросы (объединить вывод нескольких Наблюдателей)\n-Concat - соединяет вывод нескольких Наблюдателей так, что они действуют как один Наблюдаемый,при этом все элементы, испускаемые первым Наблюдаемым, испускаются перед элементами, испускаемыми вторым Наблюдаемым.\n-Zip - возвращает Observable, который применяет функцию к комбинации элементов, испускаемых последовательно двумя другими Observable, при этом результаты этой функции становятся элементами, испускаемыми возвращенным Observable.\n-CombineLatest - когда элемент испускается одним из двух "Наблюдателей",объединяет последний элемент каждого "Наблюдателя" через указанную функцию и испускает элементы\n-Join - объединяет элементы,испускаемые двумя наблюдателями,когда элемент из одного наблюдателя испускается в течение временного окна,определенного в соответствии с элементом,испускаемым другим наблюдателем.\n-And/Then/When - объединяет наборы предметов,испускаемых двумя или более Наблюдателями с помощью посредников "Pattern" и "Plan".\n-Switch - преобразовывает Наблюдатель, который испускает Наблюдатели, в единственный Наблюдатель, который испускает элементы, испускаемые самыми свежими из этих Наблюдателей.\nЯ хочу сдвинуть элементы, испускаемые Observable, вперед во времени, прежде чем переиздавать их: -Delay\nЯ хочу преобразовать элементы и уведомления из Observable в элементы и повторно отправить их, заключая их в объекты Notification: -Materialize, а обратить процесс -Dematerialize\nЯ хочу получить определенный элемент, испускаемый Observable: -последний Last -первый или первый, отвечающий условию Single -первый First',Column4:'Я хочу испускать элементы из Observable после их преобразования:\n-Map - преобразовывать элементы,излучаемые наблюдателем,путем применения к каждому элементу функции\n-flatMap - преобразует элемент Observable, применяя функцию, которую вы указываете к каждому элементу, и объединяет излучения этих результирующих элементов Observables,выбрасывая их как последовательность.\n-ConcatMap - по одному Наблюдаемому за раз,в том порядке,в котором они испускаются.\n-Scan - применять функцию к каждому элементу,испускаемому наблюдаемым,последовательно,и испускать каждое последующее значение\n-Timestamp - прикрепив к ним временную метку\n-TimeInterval - преобразовать Наблюдаемое,которое испускает элементы,в Наблюдаемое,которое испускает показания о количестве времени,прошедшего между этими выбросами.\nЯ хочу игнорировать все элементы, испускаемые Observable, и передавать только его уведомление о завершении/ошибке: -IgnoreElements\nЯ хочу отразить Observable c префиксом элементов его последовательности -StartWith\n-DefaultEmpty - испускает элементы из источника Наблюдаемый,или элемент по умолчанию,если источник Наблюдаемый ничего не испускает\nЯ хочу собирать элементы из Observable и повторно отправлять их в виде буферов элементов: -Buffer /собирать только последние элементы: -TakeLastBuffer\nЯ хочу разделить 1 Observable на несколько: -Window /чтобы похожие предметы оказались на одном и том же наблюдательном месте: -GroupBy\nЯ хочу перевыпустить только определенные элементы из Observable:\n-путем фильтрации тех, которые не соответствуют какому-то предикату - Filter\n-первый элемент -First\n-первые n элементов -Take\n-последний -Last\n-элемент указанного индекса -ElementAt\n-подавить первые n элементов -Skip\n-подавить до тех пор,пока один из этих предметов не совпадет с предикатом -SkipWhile\n-подавить после того,как "Наблюдатель" во второй раз испускает предмет - SkipUntil\n-подавить кроме последних n элементов -SkipLast\n-зеркалировать до тех пор,пока один из этих предметов не совпадет с предикатом -TakeWhile\n'},{Вопросы:"Subjects ReactiveX, виды и примеры",Ответы:"Subject — это своего рода мост или прокси, доступный в некоторых реализациях ReactiveX, который действует как Observer и Observable. Так как он является observer, он может подписаться на один и более Observables и может пройти через все элементы, за которыми он наблюдает, повторно передав их, а также может излучать(emit) новые элементы.\nSubject, которые есть в RxJava.\n- Publish Subject - Излучает(emit) все последующие элементы наблюдаемого источника в момент подписки.\nЗдесь, если студент вошел в аудиторию, он просто хочет слушать с того момента, когда он вошел в аудиторию.\nпример:\nPublishSubject<Integer> source = PublishSubject.create();\n// Получит 1, 2, 3, 4 и onComplete\nsource.subscribe(getFirstObserver());\nsource.onNext(1);\nsource.onNext(2);\nsource.onNext(3);\n// Получит 4 и onComplete для следующего наблюдателя тоже.\nsource.subscribe(getSecondObserver());\nsource.onNext(4);\nsource.onComplete();\n- Replay Subject - Излучает(emit все элементы источника Observable, независимо от того, когда подписчик(subscriber) подписывается. Здесь, если студент с опозданием вошел в аудиторию, он хочет послушать лекцию с самого начала.\nпример:\nReplaySubject<Integer> source = ReplaySubject.create();\n// Он получит 1, 2, 3, 4\nsource.subscribe(getFirstObserver());\nsource.onNext(1);\nsource.onNext(2);\nsource.onNext(3);\nsource.onNext(4);\nsource.onComplete();\n// Он также получит 1, 2, 3, 4 так как он использует Replay Subject\nsource.subscribe(getSecondObserver());",Column3:"- Behavior Subject - излучает(emit) совсем недавно созданый элемент и все последующие элементы наблюдаемого источника, когда наблюдатель присоединяется к нему. Здесь, если студент вошел в аудиторию, он хочет слушать самые последние вещи(не с начала)\nпреподаваемые профессором таким образом, что он получает идею контекста.\nПример:\nBehaviorSubject<Integer> source = BehaviorSubject.create();\n// Получит 1, 2, 3, 4 and onComplete\nsource.subscribe(getFirstObserver());\nsource.onNext(1);\nsource.onNext(2);\nsource.onNext(3);\n// Получит 3(последний элемент) и 4(последующие элементы) и onComplete\nsource.subscribe(getSecondObserver());\nsource.onNext(4);\nsource.onComplete();\n- Async Subject -  выдает только последнее значение наблюдаемого источника. Здесь, если студент пришел в любой момент времени в аудиторию, и он хочет слушать только о последней вещи(и только последней) которую учат.\nпример:\nAsyncSubject<Integer> source = AsyncSubject.create();\n// Получит только 4 и onComplete\nsource.subscribe(getFirstObserver());\nsource.onNext(1);\nsource.onNext(2);\nsource.onNext(3);\n// Тоже получит только 4 и onComplete\nsource.subscribe(getSecondObserver());\nsource.onNext(4);\nsource.onComplete();\nПримеры: Observable: Предположим, что профессор является наблюдаемым(observable). Профессор учит какой-то теме.\nObserver: Предположим, что студент наблюдатель(observer). Студент слушает(или наблюдает) тему, которую преподает профессор."},{Вопросы:"Распараллеливание потоков RxJava",Ответы:"Многопоточное приложение состоит из двух или более частей, которые могут работать параллельно. Это позволяет приложению лучше использовать ядра внутри процессора устройства, выполнять задачи быстрее и обеспечивать более плавный и отзывчивый опыт для пользователя.\nКодирование для параллелизма в Java может быть болезненным, но благодаря RxJava теперь это сделать намного проще. В RxJava объявляется поток, в котором должна выполняться задача (декларативно) вместо создания и управления потоками (обязательно).\nRxJava использует Schedulers вместе с операторами subscribeOn() и observeOn() для достижения этой цели.\nПланировщики в RxJava 2\nSchedulers в RxJava используются для выполнения единицы работы над потоком.\nScheduler предоставляет абстракцию для механизма потоков Android и Java. Если хотите запустить задачу и используете Scheduler для ее выполнения, Scheduler переходит в свой пул потоков (набор потоков, готовых к использованию), а затем запускает задачу в доступном потоке.\nМожно указать, что задача должна выполняться в одном конкретном потоке. (есть 2 оператора: subscribeOn() и observeOn(), которые можно использовать для указания, в каком потоке из пула потоков Scheduler должна быть выполнена задача.)\nВ Android длительные процессы или задачи с интенсивным использованием процессора не должны выполняться в главном потоке. Если подписка Observer на Observable проводится в основном потоке, любой связанный оператор также будет работать в основном потоке. В случае длительной задачи (например, выполнение сетевого запроса) или задачи с интенсивным использованием ЦП (например, преобразование\nизображения) это будет блокировать пользовательский интерфейс до завершения задачи, что приведет к вылетанию приложения. Вместо этого эти операторы могут быть переключены на другой поток с observeOn().",Column3:"Типы планировщиков\nВот некоторые из типов Schedulers доступных в RxJava и RxAndroid, чтобы указать тип потока для выполнения задач.\n-Schedulers.immediate() : возвращает Scheduler, который мгновенно выполняет работу в текущем потоке. Имейте в виду, что это заблокирует текущий поток, поэтому его следует использовать с осторожностью.\n-Schedulers.trampoline() : планирование задач в текущем потоке. Эти задачи не выполняются сразу, а выполняются после того, как поток завершил свои текущие задачи. Отличается от Schedulers.immediate() тем, что вместо немедленного выполнения задачи он ожидает завершения текущих задач.\n-Schedulers.newThread() : запускает новый поток и возвращает Scheduler для выполнения задачи в новом потоке для каждого Observer . При этом новый поток не используется повторно, а уничтожается.\n-Schedulers.computation() : дает Scheduler, который предназначен для вычислительно-интенсивной работы, такой как преобразование изображений, сложные вычисления и т. Д. Эта операция полностью использует ядра ЦП. Этот Scheduler использует фиксированный размер пула потоков, который зависит от ядер ЦП для оптимального использования. Вы должны быть осторожны, чтобы не создавать больше\nпотоков, чем доступные ядра ЦП, поскольку это может снизить производительность.\n-Schedulers.io() : создает и возвращает Scheduler, предназначенный для работы, связанной с вводом-выводом, такой как выполнение асинхронных сетевых вызовов или чтение и запись в базу данных. Эти задачи не загружают процессор, используют Schedulers.computation() .\n-Schedulers.single() : создает и возвращает Scheduler и выполняет несколько задач последовательно в одном потоке.\n-Schedulers.from(Executor executor) : создает Scheduler, который будет выполнять задачу или единицу работы с данным Executor .\n-AndroidSchedulers.mainThread() : создает Scheduler, который выполняет задачу в главном потоке приложения Android. Этот тип планировщика предоставляется библиотекой RxAndroid .\r"},{Вопросы:"Для чего нужен оператор subscribeOn()",Ответы:"задает Scheduler, на котором выполняется подписка на Observable . Другими словами, код метода Observable. create() выполняется в потоке, заданном subscribeOn() . Scheduler , который задает subscribeOn() действует от создания Observable и вниз по цепочке вызовов RxJava до первого observeOn()"},{Вопросы:"Параллелизм с оператором flatMap()",Ответы:'flatMap() включает параллелизм, разделяя поток событий на поток подпотоков\n \n Observable.flatMap() принимает на вход данные, излучаемые одним Observable, и возвращает данные, излучаемые другим Observable, подменяя таким образом один Observable на другой. Неожиданный поворот событий, так сказать: вы думали, что получаете один поток данных, а получаете на самом деле другой.\n Пример кода:\n query("Hello, world!")\n  .flatMap(urls -> Observable.from(urls))\n  .subscribe(url -> System.out.println(url));'},{Вопросы:"Интерфейс Flowable",Ответы:'Чтобы понять Flowables, нам сначала нужно понять Observables. Наблюдаемые - это те объекты, которые мы наблюдаем за любым событием. Наблюдаемые используются, когда у нас относительно мало элементов за время и нет риска переполнения потребителей. Если есть вероятность того, что потребитель может быть переполнен, используем Flowable. Одним из примеров может быть получение огромного количества данных с датчика. Обычно они отправляют данные с высокой скоростью. В предыдущей версии RxJava это переполнение можно было предотвратить, применив противодавление. Но в RxJava 2 команда разработчиков разделила эти два типа производителей на две сущности: наблюдаемые и текучие.\n Пример переполнения с Observables:\n val observable = PublishSubject.create<Int>()\n  observable.observeOn(Schedulers.computation())\n  .subscribeBy (\n  onNext ={\n  println("number: ${it}")\n  },onError = {t->\n  print(t.message)\n  }\n  )\n  for (i in 0..1000000){\n  observable.onNext(i)\n  }\n \n Пример с Flowables:\n val observable = PublishSubject.create<Int>()\n  observable\n  .toFlowable(BackpressureStrategy.MISSING)\n  .observeOn(Schedulers.computation())\n  .subscribeBy (\n  onNext ={\n  println("number: ${it}")\n  },onError = {t->\n  print(t.message)\n  }\n  )\n  for (i in 0..1000000){\n  observable.onNext(i)\n  }',Column3:"Стратегии с Flowables:\n *Отбрасывание. Что вы делаете, когда не можете справиться со слишком многими вещами? Вы бросаете это. Эта стратегия обратного давления делает то же самое. Он отбрасывает элементы, если он не может обработать больше, чем его емкость, т.е. 128 элементов (размер буфера). Есть два способа применить эту стратегию обратного давления:\n \n 1)observable.toFlowable(BackpressureStrategy.DROP)\n or\n 2)observable.toFlowable(BackpressureStrategy.MISSING).onBackpressureDrop()\n \n *Сохранить последний элемент: если производитель видит, что нисходящий поток не может справиться с потоком элементов, он прекращает его отправку и ждет, пока он не станет доступным. В то же время он продолжает отбрасывать элементы, кроме последнего, который прибыл, и отправляет последний, когда нисходящий поток снова становится доступен. Есть два способа применить эту стратегию противодавления:\n \n 1)observable.toFlowable(BackpressureStrategy.LATEST)\n or\n 2)observable.toFlowable(BackpressureStrategy.MISSING).onBackpressureLatest()\n \n *Буферизация: возможно, это не лучший способ справиться с большим количеством выбросов, но, безусловно, это доступный способ. При этом вы можете сохранять элементы в буфере. В этом случае элементы хранятся в буфере до тех пор, пока они не будут обработаны. Есть два способа применить эту стратегию противодавления:\n \n 1)observable.toFlowable(BackpressureStrategy.BUFFER)\n or\n 2)observable.toFlowable(BackpressureStrategy.MISSING).onBackpressureBuffer()\n \n Вы также можете указать размер буфера как:\n \n observable.toFlowable(BackpressureStrategy.MISSING).buffer(10)"},{Вопросы:"Backpressure RxJava",Ответы:"Противодавление — это процесс обработки быстрого производителя предметов, например. когда конвейер обработки Observable не может обрабатывать значения достаточно быстро и может столкнуться с исключением Out of Memory, тогда нам нужен способ сообщить вышестоящему производителю о замедлении, этот механизм называется Backpressuring или Backpressure. Проще говоря, мы можем сказать, что когда у нас слишком много данных, передаваемых наблюдателям, и наблюдатели не могут их обработать и сталкиваются с исключением Out of Memory, чтобы предотвратить это, мы должны (обратное давление) сказать вышестоящему производителю замедлить работу."},{Вопросы:"Разница между Observable и Flowable",Ответы:"Противодавление было причиной того, что Flowable был введен в RxJava 2.x, поскольку основное различие между Observable и Flowable заключается в том, что Flowables осведомлены о противодавлении, а Observable — нет. Класс Observable имеет неограниченный размер буфера, т.е. Наблюдаемый объект будет буферизовать все и отдавать все подписчику в один момент времени, поэтому в то время, когда Observable был введен в RxJava 0.x, обратное давление не было включено в него, однако с RxJava 2.x у нас есть новый Observable объектный класс, называемый Текучесть с включенным противодавлением.\n Observable используются, когда у нас есть относительно небольшое количество объектов, которые нужно генерировать с течением времени (<1000), и нет риска , что производитель переполнит потребителей, что может привести к OutOfMemoryException.\n Flowable используются, когда у нас относительно большое количество элементов, и нам нужно тщательно контролировать их Producer поведение, чтобы избежать исчерпания ресурсов или перегрузки."},{Вопросы:"протокол Rsocket, принцип работы",Ответы:"RSocket — это протокол приложений для реактивных потоков, который обеспечивает управление потоком приложений по сети, чтобы предотвратить сбои и повысить отказоустойчивость. В отличие от HTTP, RSocket не ожидает ответа или запроса от клиента.\n \n Взаимодействие в RSocket разбито на фреймы. Каждый кадр состоит из заголовка кадра, который содержит идентификатор потока, определение типа кадра и другие данные, относящиеся к типу кадра. За заголовком кадра следуют метаданные и полезная нагрузка — эти части несут данные, указанные пользователем.\n \n Следует отметить, что RSocket не различает клиента и сервер после фазы настройки соединения. Каждая сторона может начать отправку данных другой — это делает протокол почти полностью симметричным.\n \n Кадры отправляются в виде потока байтов. Это делает RSocket более эффективным, чем обычные текстовые протоколы.\n \n Следующим фактором, который оказывает огромное влияние на производительность RSocket, является мультиплексирование. Протокол создает логические потоки (каналы) поверх единственного физического соединения. Каждый поток имеет свой уникальный идентификатор, который в некоторой степени можно интерпретировать как очередь."},{Вопросы:"MapReduce это? Пример",Ответы:"MapReduce – это модель программирования для написания приложений, которые могут обрабатывать большие данные параллельно на нескольких узлах. MapReduce предоставляет аналитические возможности для анализа огромных объемов сложных данных.\n \n Пример\n Предположим, у нас есть данные о сотрудниках в четырех разных файлах (имя, зп).\n \n Фаза Map обрабатывает каждый входной файл и предоставляет данные о сотруднике в парах ключ-значение (<k, v>: <emp name, salary>)\n Фаза объединителя (метод поиска) будет принимать входные данные из фазы карты в виде пары ключ-значение с именем сотрудника и зарплатой. Используя технику поиска, комбинатор проверит всю зарплату сотрудника, чтобы найти сотрудника с наибольшим окладом в каждом файле.\n \n <k: employee name, v: salary>\n Max= the salary of an first employee. Treated as max salary\n if(v(second employee).salary > Max){\n  Max = v(salary);\n }\n else{\n  Continue checking;\n }\n Ожидаемый результат: наибольшая зарплата сотрудника в каждом файле\n \n Этап сокращения – Сформируйте каждый файл, вы найдете самый высокооплачиваемый сотрудник. Чтобы избежать избыточности, проверьте все пары <k, v> и удалите дублирующиеся записи, если таковые имеются."},{Вопросы:"Что такое большие данные?",Ответы:"Большие данные — обозначение структурированных и неструктурированных данных огромных объёмов и значительного многообразия, эффективно обрабатываемых горизонтально масштабируемыми программными инструментами, появившимися в конце 2000-х годов и альтернативных традиционным системам управления базами данных и решениям класса Business Intelligence."},{Вопросы:"Как работает MapReduce?",Ответы:"Традиционные корпоративные системы обычно имеют централизованный сервер для хранения и обработки данных. Традиционная модель, безусловно, не подходит для обработки огромных объемов масштабируемых данных и не может быть размещена на стандартных серверах баз данных.\n\nMapReduce делит задачу на маленькие части и назначает их многим компьютерам. Позже результаты собираются в одном месте и объединяются для формирования результирующего набора данных.\r Алгоритм MapReduce содержит две важные задачи, а именно Map и Reduce.\n\n map берет набор данных и преобразует его в другой набор данных, где отдельные элементы разбиваются на кортежи (пары ключ-значение). \n reduce принимает выходные данные из карты в качестве входных данных и объединяет эти кортежи данных (пары ключ-значение) в меньший набор кортежей. Задача уменьшения всегда выполняется после задания карты."},{Вопросы:"Этапы MapReduce",Ответы:"Теперь внимательно рассмотрим каждый из этапов. \n Фаза ввода – есть Record Reader, который переводит каждую запись во входной файл и отправляет проанализированные данные в маппер в виде пар ключ-значение. \n Карта – пользовательская функция, которая принимает серию пар ключ-значение и обрабатывает каждую из них, чтобы сгенерировать ноль или более пар ключ-значение. \n Промежуточные ключи – пары «ключ-значение», генерируемые картографом, называются промежуточными ключами. \n Объединитель – тип локального редуктора, который группирует аналогичные данные из фазы карты в идентифицируемые наборы. Принимает промежуточные ключи от преобразователя в качестве входных данных и применяет пользовательский код для агрегирования значений в небольшой области одного преобразователя. Он не является частью основного алгоритма MapReduce; это необязательно.\n Перемешать и отсортировать – задача «Восстановитель» начинается с шага «Перемешать и сортировать». Он загружает сгруппированные пары ключ-значение на локальный компьютер, на котором работает редуктор. Отдельные пары ключ-значение сортируются по ключу в больший список данных. Список данных группирует эквивалентные ключи вместе, так что их значения могут быть легко повторены в задаче Reducer.\n Редуктор – принимает сгруппированные парные данные ключ-значение в качестве входных данных и запускает функцию Редуктор для каждого из них. Здесь данные могут быть агрегированы, отфильтрованы и объединены различными способами, что требует широкого спектра обработки. Как только выполнение закончено, он дает ноль или более пар ключ-значение для последнего шага. \n Фаза вывода. Есть выходной форматер, который переводит конечные пары ключ-значение из функции Reducer и записывает их в файл с помощью средства записи."},{Вопросы:"Интерфейс JobContext",Ответы:"Интерфейс JobContext – суперинтерфейс для всех классов, который определяет различные задания в MapReduce. Дает доступ только для чтения к заданию, которое предоставляется задачам во время их выполнения. Приведены подинтерфейсы интерфейса JobContext. \n№/Подинтерфейс/Описание \n1./MapContext/Определяет контекст, который предоставляется Mapper. \n2./ReduceContext/Определяет контекст, который передается редуктору. \nКласс Job – основной класс, который реализует интерфейс JobContext."},{Вопросы:"Mapper Class",Ответы:"Класс Mapper определяет задание Map. Сопоставляет входные пары ключ-значение с набором промежуточных пар ключ-значение.\nКарты – отдельные задачи, которые преобразуют входные записи в промежуточные записи. Преобразованные промежуточные записи не обязательно должны быть того же типа, что и входные записи. Заданная входная пара может отображаться на ноль или на множество выходных пар, метод map является наиболее известным методом класса Mapper.\nСинтаксис представлен map(KEYIN key, VALUEIN value, org.apache.hadoop.mapreduce.Mapper.Context context). Метод вызывается один раз для каждой пары ключ-значение во входном разбиении."},{Вопросы:"Класс Reducer",Ответы:"Класс Reducer определяет задание Reduce в MapReduce. Это уменьшает набор промежуточных значений, которые разделяют ключ, до меньшего набора значений. Реализации редуктора могут получить доступ к Конфигурации для задания через метод JobContext.getConfiguration (). Редуктор имеет три основных этапа – перемешивание, сортировка и уменьшение. \n Перемешать – Редуктор копирует отсортированный вывод из каждого Mapper, используя HTTP по всей сети. \n Сортировать – платформа объединяет сортировку входов Редуктора по ключам (поскольку разные Mappers могут выводить один и тот же ключ). Фазы тасования и сортировки происходят одновременно, т. Е. Во время выборки выходов они объединяются. \n Сокращение – На этом этапе метод Redu (Object, Iterable, Context) вызывается для каждого <ключа, (набора значений)> в отсортированных входных данных. \nметод Редукция – самый известный метод класса Редукторов. Синтаксис представлен– reduce (KEYIN key, Iterable values, org.apache.hadoop.mapreduce.Reducer.Context context) Этот метод вызывается один раз для каждого ключа в коллекции пар ключ-значение.",Column3:"Сократить"},{Вопросы:"MapReduce – реализация Hadoop",Ответы:"MapReduce – инфраструктура, которая используется для написания приложений для надежной обработки огромных объемов данных на больших кластерах аппаратного оборудования.",Column3:"Сократить"},{Вопросы:"Алгоритм MapReduce",Ответы:"Алгоритм MapReduce Обычно парадигма MapReduce основана на отправке программ сокращения карт на компьютеры, где хранятся фактические данные. \n Во время задания MapReduce Hadoop отправляет задачи Map и Reduce на соответствующие серверы в кластере. \n Каркас управляет всеми деталями передачи данных, такими как выдача задач, проверка выполнения задач и копирование данных вокруг кластера между узлами. \n Большая часть вычислений происходит на узлах с данными на локальных дисках, что снижает сетевой трафик. \n После выполнения заданной задачи кластер собирает и сокращает данные, чтобы сформировать соответствующий результат, и отправляет их обратно на сервер Hadoop.",Column3:"Сократить"},{Вопросы:"Как работает Combiner?Что такое Combiner?Реализация",Ответы:"Краткое описание того, как работает MapReduce Combiner: \n · У объединителя нет предопределенного интерфейса, и он должен реализовывать метод Redu () интерфейса Reducer. \n · Комбайнер работает с каждым ключом вывода карты. Он должен иметь те же типы значений выходного ключа, что и класс Reducer. \n · Объединитель может создавать сводную информацию из большого набора данных, поскольку он заменяет исходный вывод карты. \n Хотя Combiner не является обязательным, он помогает разделить данные на несколько групп для фазы сокращения, что упрощает обработку.\n \n Combiner, также известный как полуредуктор, является необязательным классом, который\n работает, принимая входные данные из класса Map и затем передавая выходные пары ключзначение в класс Reducer.\n Основная функция Combiner состоит в том, чтобы суммировать выходные записи карты с одним\n и тем же ключом. Выход (сбор значения ключа) объединителя будет отправлен по сети\n фактической задаче «Редуктор» в качестве входных данных.\n Класс Combiner используется между классом Map и классом Reduce для уменьшения объема\n передачи данных между Map и Reduce \n \n public static class IntSumReducer extends Reducer<Text,IntWritable,Text,IntWritable>\n {\n  private IntWritable result = new IntWritable();\n \n  public void reduce(Text key, Iterable<IntWritable> values,Context context) throws IOException, InterruptedEx\n ception\n  {\n  int sum = 0;\n  for (IntWritable val : values)\n  {\n  sum += val.get();\n  }\n  result.set(sum);\n  context.write(key, result);\n  }\n }",Column3:"Сократить"},{Вопросы:"Основы блокчейн технологий",Ответы:"блокчейн — это децентрализованная база данных, которая предназначена для хранения последовательных блоков с набором характеристик (версия, дата создания, информация о предыдущих действиях в сети). Выстроенная по определенным правилам непрерывная последовательная цыпочка блоков, содержащих информацию. Связь между блоков обеспечивается не только нумерацией, но и тем, что каждый блок содержит свою собственную хеш-сумму и хеш-сумму предыдущего блока. Для изменения информации в блоке необходимо редактировать все последующие блоки. Чаще всего копии цепочек блоков хранятся на множестве разных компьютеров, независимо друг от друга. Это делает крайне затруднительным внесение изменений в информацию, уже включенную в блоки."},{Вопросы:"Принципы блокчейн",Ответы:"Основные принципы блокчейн:\n* Распределенный гроссбух, или регистр 2.0, построен по принципу книги учета и распределен между всеми участниками.\n* Децентрализация и отказ от посредничества: Блокчейн не контролируется никаким центральным органом, в этой доверительном системе отношений между двумя участниками нет третьих лиц.\n* Консенсус: Факт принятия транзакции или отказа от нее является результатом распределенного консенсуса, а не решения некоего централизованного института.\n* Неизменность и устойчивость: Невозможно изменить или уничтожить записи.\n* Распределенное доверие и прозрачность: Разделяются данные, операции и консенсус."},{Вопросы:"Децентрализация и распределенность",Ответы:"Децентрализация - система блокчейн, где каждый блок с информацией копируется одновременно на тысячи устройств без главенствующих в структуре систем. Участником сети может стать каждый: достаточно установить официальный кошелек и загрузить полную ноду к себе на диск. С этого момента компьютер станет полноправным узлом в сети.\n Чем больше людей используют блокчейн, тем мощнее и безопаснее он становится.\n \n Просто определения понятий из инета на всякий случай: \n Децентрализованная сеть - это одноранговая сеть, в которой каждый узел (нода) самостоятелен и может устанавливать соединения с любым другим узлом сети для достижения некой цели, а не в результате координации какого-либо центра влияния.\n Распределенная сеть - это сеть, в которой управление узлами может осуществляется из нескольких местных центров, каждый из которых может быть взаимосвязан, как напрямую, так и через узлы-посредники.",Column3:"Сократить"},{Вопросы:"Транзакции в блокчейн",Ответы:"операция сохранения данных в блокчейне, в ходе которой происходит передача криптоактивов или другой информации между кошельками. Отправка транзакции происходит после её создания в кошельке и подписания цифровой подписью на основе закрытого ключа.",Column3:"Сократить"},{Вопросы:"Криптография в блокчейн",Ответы:'В блокчейне используется 3 вида криптографии: хеш-функции, ассиметричное и симметричное шифрование. Является компонентом "криптографической истины". Чтобы понять че это значит надо посмотреть на картинку справа'},{Вопросы:"Хеш-функции в блокчейн",Ответы:"Хэш-функция осуществляет превращение информации транзакций в зашифрованные хэши, составляющие базовую основу блокчейна. Фактически хэш является новым состоянием блокчейна, который содержит в себе уже новую информацию о транзакциях.\nХэш-функцию используют к информации любого объема, а потом меняют на данные уже ограниченного объема, обеспечивая защиту, хранение, передачу данных."},{Вопросы:"Симметричное шифрование в блокчейн",Ответы:'Предполагает использование общего секретного ключа, который отправитель и получатель используют для шифрования и расшифровки сообщений. В симметричном шифровании используется один и тот же ключ и для шифрования и для расшифровки. Примером алгоритма симметричного шифрования является, например AES. Кроме того, симметричное шифрование требует наличие алгоритма для защищенного обмена ключами перед началом "общения".'},{Вопросы:"Асимметричное шифрование в блокчейн",Ответы:"Метод шифрования, при котором каждый участник имеет открытый и закрытый ключ. При шифровании сообщния открытым ключом, расшифровать его может только пользователь с закрытым ключом. Таким образом достигается конфиденциальность. При этом открытые ключи можно безпрепятственно передавать, в то время как закрытые ключи должны быть известны только каждому непосредственныму участнику общения"},{Вопросы:"Обработка транзакции в блокчейн",Ответы:"Транзакция – это отдельная операция в блокчейне от имени участника, изменяющая стейт сети. Отправляя ту или иную транзакцию, участник отправляет в сеть запрос с набором данных, необходимых для соответствующего изменения стейта.\nПеред отправкой транзакции участник генерирует для нее цифровую подпись. Для этого он использует закрытый ключ своего аккаунта. Подписание транзакций может осуществляться 3 способами:\n-посредством клиента блокчейн-платформы;\n-при помощи метода REST API;\n-при помощи JavaScript SDK.\n\nПодпись транзакции записывается в поле proofs при отправке транзакции в блокчейн. Как правило, в это поле записывается 1 подпись участника, отправившего транзакцию. Однако поле поддерживает до 8 подписей: в случае подписания транзакции смарт-аккаунтом, при заполнении атомарной транзакции или при публикации смарт-контракта.\nПосле подписания транзакция отправляется в блокчейн – это можно сделать 3 способами, которые указаны выше, и при помощи gRPC-интерфейса.\nПолучив транзакцию, нода проверяет ее на валидность:\n1.Соответствие временной метки (timestamp): временная метка транзакции должна отклоняться от временной метки текущего блока не более, чем на 2 часа назад или 1,5 часа вперед.\n2.Тип и версия транзакции: активирована ли в блокчейне поддержка транзакций указанного типа и версии.\n3.Соответствие полей транзакции заданному типу данных;\n4.Проверка баланса отправителя: достаточно ли средств для оплаты комиссии;\n5.Проверка подписи транзакции.\n\nЕсли транзакция не проходит валидацию, нода отклоняет ее. В случае успешного прохождения проверок транзакция добавляется в пул неподтвержденных транзакций (UTX-пул), где ожидает следующего раунда майнинга для передачи в блокчейн. Вместе с передачей транзакции в UTX-пул нода рассылает ее другим нодам в сети.\nПоскольку у каждого микроблока есть ограничение на количество поступающих транзакций, отдельная транзакция может попасть из UTX-пула в блокчейн далеко не сразу. Во время нахождения транзакции в UTX-пуле транзакция может стать невалидной. Например, ее временная метка перестала соответствовать параметрам временной метки текущего блока, либо транзакция, попавшая в блокчейн, уменьшила баланс отправителя, сделав его недостаточным для оплаты транзакции. В таком случае транзакция отклоняется и удаляется из UTX-пула.\nПосле добавления в блок транзакция меняет стейт блокчейна. После этого транзакция считается выполненной."},{Вопросы:"Атака Сивиллы",Ответы:"Атака Сивиллы (англ. Sybil attack) – это угроза безопасности, которая подразумевает контроль одним человеком или группой лиц над множеством сетевых узлов (нод) в одноранговой сети (P2P). Такую схему применяют для захвата контроля над сетью для ее использования в собственных целях, например, для фальсификации данных.\nВ контексте рынка криптовалют атаки Сивиллы работают похожим образом. Мошенники создают множество нод и подключают их к сети криптовалюты. Технически, сетевые узлы будут выглядеть независимыми. При этом управлять ими может один человек. Подконтрольные мошеннику ноды способны склонять другие сетевые узлы к одобрению искаженных данных."},{Вопросы:"Хранение данных в блокчейн",Ответы:"Блокчейн — реестр, содержащий все транзакции, которые когда-либо происходили в сети в хронологическом порядке (некоторые блокчейны изучают возможность обрезки исторических данных после определенной контрольной точки). Чем дольше работает блокчейн, тем больше становится реестр и тем дороже узлам обходится ее хранение и синхронизация. Чрезмерные требования к хранению и пропускной способности ставят под угрозу децентрализацию сети блокчейн, поскольку увеличивают аппаратные требования к работе узла, что потенциально позволяет небольшой группе субъектов нарушить работу сети.\nДля эффективного и безопасного кодирования данных реестра блокчейн использует деревья Меркла. В дереве Меркла транзакция пользователя хэшируется, затем сопоставляется с другой хэшированной транзакцией и снова хэшируется. Хеши сопоставляются и хешируются вверх по дереву, пока не образуется единый хеш всех хешей, корень Меркла.\nБиткойн использует дерево Меркла для транзакций на основе модели “Неизрасходованный выход транзакции” (UTXO), а Ethereum - для транзакций, состояния и квитанций (журналов и событий) в модели учётной записи с обобщенной поддержкой смарт-контрактов.\nДеревья Меркла — эффективный способ хранения данных о транзакциях в блокчейн.\n+ Они занимают меньше дискового пространства по сравнению с другими структурами данных и способствуют эффективной проверке целостности данных и включению данных в распределённый реестр.\n+ Поскольку корни Меркла включаются в заголовки блоков, они позволяют легким клиентам, подключенным к доверенному полному узлу, быстро и безопасно проверить, что конкретная транзакция была включена в блок, не загружая весь блокчейн.\n\nНекоторые из других криптографических примитивов в блокчейне:\n- Доказательства нулевого знания (ZKPs) — метод, позволяющий проверяющему доказать проверяемому, что он обладает знаниями о конкретной части информации, не раскрывая фактической информации, лежащей в основе. Например, в блокчейне Zcash полные узлы могут доказать, что транзакции действительны, не зная ни отправителя, ни получателя, ни суммы транзакции.\n- Доверенные среды выполнения (TEEs) — использование доверенного оборудования, такого как Intel SGX, для выполнения конфиденциальных вычислений, где целостность вычислений может быть доказана криптографическими сертификатами. Пример: блокчейн Oasis, где все узлы-валидаторы используют доверенные среды выполнения для обеспечения конфиденциального и проверяемого выполнения смарт-контрактов.\n- Пороговые схемы подписи (TSS) — форма распределенной генерации и подписи ключей, используемая для аутентификации вычислений, выполняемых децентрализованной сетью, с помощью одной криптографической подписи, для подписания которой требуется только пороговый набор участников. Например, транзакция, которую должны подписать только 10 из 15 узлов, чтобы она считалась действительной.",Column3:"Сократить"},{Вопросы:"Блокчейн консенсус",Ответы:"Консенсус в блокчейне – это соглашение большинства участников сети касательно распределения данных, которое приводит к подтверждению транзакции. \nАлгоритм консенсуса – это своего рода механизм, где заложены правила работы сети и условия, при которых может быть достигнуто общее соглашение."},{Вопросы:"Одноранговые сети",Ответы:"Почему именно «одноранговые»? Если рассматривать ситуацию с точки зрения информационных технологий, то одноранговые или пиринговые (от peer-to-peer) сети – это такие сети, в которых отельные элементы (узлы) обмениваются между собой файлами и хранят один и тот же набор данных. Узлы равны по мощности и выполняют одинаковые по смыслу задачи. С финансовой точки зрения, одноранговые сети – финансовые платформы, которые позволяют осуществлять финансовые операции купли-продажи без посредников. В некоторых ситуациях, аналогичным образом организуются и процедуры получения и выдачи кредитов. В любом случае, о первых эффективных одноранговых сетях начали говорить примерно в девяностых годах прошлого века, когда появились программы для эффективного обмена файлами. Однако основной интерес к ним вспыхнул после появления криптовалютных сетей, основанных на классической P2P-архитектуре. Впрочем, теперь такие сети используются не только в криптоэкономике, но и при создании поисковых систем, стриминг-платформ, разнообразных онлайн-рынков и в рамках межпланетной файловой системы IPFS. Как это работает? Итак. У нас есть большое количество связанных друг с другом компьютеров. На каждом из них хранится копия всех файлов, содержащихся в сети. Это позволяет одновременно выполнять и роль клиента, и роль сервера. Кроме того, узлы равны в своих правах, так что ни у кого нет преимущества перед остальными, а решения о глобальных изменениях принимаются коллегиально. Эта ситуация позволяет каждому узлу одновременно закачивать новую информацию и раздавать уже хранящуюся. Процесс этого постоянен и непрерывен, поскольку все узлы обязаны реагировать на любое изменение содержимого сети. Независимое хранение информации на разных источниках делает всю систему более устойчивой к внешним воздействиям и взломам. Кроме того, в сетях Р2Р нет единой точки отказа, в отличие от централизованных систем. Классификация Выделяют три основных типа одноранговых сетей.  Неструктурированные. Узлы случайным образом контактируют друг с другом, что обеспечивает высокую активность системы даже при значительной текучке узлов. Относительно просты в построении, однако требуют больших мощностей при работе. Дело в том, что поисковые или любые другие запросы отправляются на максимально возможное число машин одновременно, так что сеть перегружается «пустыми» информационными запросами, которые могут помешать прохождению отзывов.  Структурированные. Узлы объединены в строгую систему со своей архитектурой. В такой системе активно используется поиск по хэш-функциям, что значительно снижает общую интенсивность информационного потока. Однако такие системы в некоторой степени уже являются централизованными, поэтому куда более требовательны к обслуживанию и установке. Да и при временном выпадении большой группы узлов, вся работа системы нарушается.  Гибридные. Комбинация предыдущих вариантов. Например, наличие центрального сервера, упрощающего процесс обмена между отдельными узлами. Как правило, подобные сети отличаются высокой производительностью и устойчивостью. Р2Р и блокчейн Когда Сатоши Накамото создавал сеть Биткоин, он сформулировал её как «одноранговая платёжная система электронных денежных средств». Это обеспечивалось благодаря работе новой технологии – блокчейн. Технология позволяла обмениваться цифровой валютой с участниками по всему миру без использования услуг посредников и центральных серверов. Кроме того, любой желающий мог присоединиться к этому процессу. Роль банков, фиксирующих и гарантирующих подлинность финансовых операций, взял на себя цифровой регистр, в котором фиксируется вся активность и к которому может обратиться любой желающий. Проще говоря, каждый узел, подключенный к сети, хранит всю информацию, содержащуюся в ней, и регулярно связывается с другими узлами, чтобы гарантировать достоверность и актуальность хранимой информации. Но несмотря на то, что сеть является одноранговой, разные узлы могут брать на себя разные функции. Так, например, существуют так называемые «полные ноды», основная задача которых - проверка транзакций в системе на предмет соответствия их действующим алгоритмам консенсуса. А есть и другие узлы – майнеры, основная задача которых – генерация новых блоков хранения информации. Преимущества  Высокая устойчивость к DoS-атакам, поскольку информация не хранится в одном месте, а пропускная способность сети позволяет одновременно обрабатывать множество запросов.  Высокая устойчивость к изменению уже внесённой информации. Чтобы переписать данные на всех машинах сети, нужно мощность, превышающая половину общей мощности системы. Это называется «Атака 51 процента». Довольно редкое явление, особенно в больших сетях.  Высокая устойчивость к внутренним ошибкам и противоречивым сигналам. Сети Р2Р демонстрируют высокую «византийскую отказоустойчивость».  Устойчивость к внешней цензуре. Криптовалютные кошельки, например, не могут быть заморожены решением судов и правительств, в отличие от счетов в банках. Недостатки  Чем больше сеть, тем больше вычислительной работы нужно проделать, чтобы обеспечить актуальность хранимой информации. За счёт этого, замедляется общая скорость работы. Эта проблема известна как «проблема масштабируемости». И очень немногие одноранговые сети нашли более-менее приемлемые способы её решения. Примерами этого могут служить Lightning Network, Ethereum Plasma и протокол Mimblewimble.  Возможна ситуация «разделения» цепочки информации на две – ситуация «хардфорка». В таком случае, оба новых разветвления оказываются уязвимыми перед атакой повторного воспроизведения (достоверная транзакция с одной цепочки дублируется на второй, за счёт чего – снимается в 2 раза больше денег). А если учесть, что подобные хардфорки случаются регулярно, то приходится дополнительно обеспечивать защиту от них.  Невозможность исправления информации может быть и минусом. Изъять, например, компрометирующие данные из такой сети – крайне сложно. Как и цифровые копии, связанные с нарушением авторских прав. Вывод Одноранговая архитектура заметно улучшила эффективность хранения информации, сделав обмен более прозрачным, устойчивым и быстрым. Причём не только в рамках криптовалютных сетей, но и при обмене информацией иного рода – от файлов пиринговых сетей, типа torrent, до информации, связанной с крупными торговыми операциями или обработкой больших массивов цифровых данных.",Column3:"Сократить"},{Вопросы:"Proof of Work",Ответы:"Proof of Work (PoW) — это механизм предотвращения двойного расходования. Большинство криптовалют использует его в качестве алгоритма консенсуса, который служит способом защиты реестра.\nProof of Work — первый и самый популярный алгоритм консенсуса. Он был представлен Сатоши Накамото в вайтпейпере Биткоина, опубликованном в 2008 году, но сама технология была предложена задолго до этого.\nАлгоритм Proof-of-Work (PoW) позволяет участникам блокчейн-сети знать, была ли предлагаемая им информация создана бесплатно или её авторам пришлось серьёзно вложиться в её создание."},{Вопросы:"Смарт-контракты Blockchain",Ответы:"В мире криптовалют смарт-контракт — это приложение, работающее на блокчейне. Оно выступает в качестве цифрового соглашения, подкрепляемого набором правил. Эти правила определяются компьютерным кодом, который копируют и обрабатывают все ноды сети.\nСмарт-контракты позволяют создавать протоколы, не требующие доверия. Это означает, что обе стороны могут взаимодействовать через блокчейн без необходимости доверять друг другу."},{Вопросы:"Операторы Flux / Mono в Reactor",Ответы:"Flux - это Publisher, который может испускать от 0 до N элементов, а Mono может испускать от 0 до 1 элемента. Оба они завершаются либо сигналом завершения, либо ошибкой, и они вызывают методы onNext, onComplete и onError нижестоящего подписчика. Помимо реализации функций, описанных в спецификации Reactive Streams, Flux и Mono предоставляют набор операторов для поддержки преобразований, фильтрации и обработки ошибок."},{Вопросы:"Категории Reactor",Ответы:"Reactor предоставляет длинный список операторов, и в качестве помощи в поиске подходящего оператора для конкретного варианта использования есть специальное приложение в справочной документации Reactor. Он разделен на различные категории, как показано в таблице."},{Вопросы:"Работа с backpressure в Reactor",Ответы:"Backpressure (back pressure) – это то, с чем рано или поздно сталкивается почти любой разработчик, а для некоторых это становится частой и серьезной проблемой. В мире программирования термин “backpressure” является аналогией, позаимствованной из физики. В двух словах, backpressure – это сопротивление или некоторая сила, действующая в направлении, противоположном желаемому направлению движению частиц в трубе. В контексте программирования эту фразу можно переиначить: …это сопротивление желаемому потоку данных приложения. Цель любого приложения – это получение входных данных и приведение их к некоторому желаемому виду. Когда возникает backpressure, между входом и выходом возникает некое сопротивление. В большинстве случаев, узкое место возникает из-за ограничений в вычислительных мощностях – данные не успевают обрабатываться с всё нарастающей скоростью их поступления. Но есть и другие формы backpressure, например, когда приложение ожидает реакции пользователя на некоторое событие, которая, по понятным причинам, может запаздывать. Иногда под backpressure понимается не само явление как таковое, а конкретный механизм его обработки. Пример чтения и записи файлов Запись файла процесс более медленный, чем чтение. Если комбинация ОС, жесткого диска и библиотек обеспечивает эффективную скорость чтения в 150 мб/с, а записи – в 100 мб/с, то при чтении файла с последующей его записью обратно на диск, вы должны записывать в буфер “лишние” 50 мб каждую секунду. Решение очевидно: читать ровно столько, сколько сможете записать. Практически все библиотеки имеют соответствующие абстракции для работы с этими случаями. Взаимодействие между серверами Микросервисная архитектура, где каждый микросервис может разворачиваться на отдельном сервере, пользуется все большей популярностью. Backpressure в этом случае возникает, когда один сервер отправляет запросы другому слишком быстро и второй сервер не успевает их обрабатывать. Предположим, что Сервер A отправляет Серверу B 100 запросов в секунду, но Сервер B может обрабатывать только 75 из них. Имеем дефицит в 25 запросов в секунду. В любом случае, Сервер B должен каким-то образом работать с backpressure. Один из вариантов – это буферизация избыточных запросов, но если они будут сыпаться с прежней скоростью, однажды свободная память сервера закончится. Можно игнорировать избыточные запросы, но во многих случаях это запрещается требованиями к системе. Идеальный случай, когда Сервер B может сам контролировать поток запросов от Сервера А, но и это не всегда возможно. Например, если Сервер А генерирует запросы от имени пользователя. Мы же не можем сказать пользователям “притормозите!” (хотя иногда стОит!).",Column3:"Сократить"},{Вопросы:"Spring WebFlux",Ответы:"Исходный веб-фреймворк для Spring - Spring Web MVC - был построен для Servlet API и контейнеров Servlet. WebFlux был представлен как часть Spring Framework 5.0. В отличие от Spring MVC, он не требует Servlet API. Он полностью асинхронный и неблокирующий, реализует спецификацию Reactive Streams через проект Reactor. WebFlux требует Reactor в качестве основной зависимости, но он также может взаимодействовать с другими реактивными библиотеками через Reactive Streams. Spring WebFlux поддерживает две разные модели программирования: на основе аннотаций и функциональную.",Column3:"Сократить"},{Вопросы:"Стратегии backpressure",Ответы:"Помимо увеличения производительности серверного железа, остаётся три опции:\n- Контролировать источник (увеличивать частоту или снижать – решает приёмник)\n- Буферизация (временно хранить запросы, которые не были обработаны “на лету”)\n- Игнорировать (пропускать обработку части запросов)\n\nКонтроль источника – лучший вариант. Если говорить о случаях реального применения, то единственный возможный оверхэд – реализация самого механизма контроля. К сожалению этот вариант не всегда реализуем. Например случай с валом пользовательских запросов самый очевидный, ведь не так-то просто договориться с пользователями! Буферизация обычно выбирается в качестве следующего пути решения проблемы. Но надо держать в уме, что неограниченная буферизация опасна, так как приводит к утечкам памяти с последующим падением сервера. Зачастую лучше начать игнорировать запросы, чем продолжать складывать их в буфер, отнимая остатки памяти у сервера. Игнорирование входящих запросов это последняя стратегия, которая часто сочетается с буферизацией. Обычно “сбрасывают” какую-то часть запросов ежесекундно, чтобы увеличить время существования буфера. Укрощаем backpressure Существует ряд паттернов, которые чаще всего используются при работе с backpressure вне зависимости от используемого языка программирования. Pull С использованием pull-стримов потребитель контролирует источник. Обычно это вариант работы 1 к 1, то есть запрос – ответ, но есть паттерны и для request(n) (например Flowables в RxJava). Push В push-стримах источник направляет сообщение в сторону потребителя если последний доступен и готов обработать запрос. Обычно такие стримы используются при обработке действий пользователя. Существует множество библиотек, самая популярная из которых – RxJava. Немного сетевой теории Для понимания механизма работы backpressure в фреймворке WebFlux нужно вспомнить, какой транспортный протокол используется при взаимодействии по умолчанию. Обычно серверы общаются между собой через TCP-соединения. TCP скорее взаимодействует с байтами, чем с элементами логики приложения. Обычно, когда говорят о backpressure, подразумевают контроль количества принятых или отправленных по сети логических объектов и, хотя TCP имеет собственные средства для контроля потоков, они всё же работают для байтов, а не для объектов.",Column3:"Сократить"},{Вопросы:"TCP Flow control",Ответы:"Flow control (далее – контроль потока) означает, что TCP гарантирует, что отправитель не подавляет получателя , отправляя пакеты быстрее, чем тот может их обработать. Это и есть backpressure в контексте транспортного уровня модели OSI. Идея в том, что получатель даёт отправителю обратную связь с данными о своём текущем статусе. Что происходит, когда мы отправляем данные по сети? Отправитель записывает данные в сокет, транспортный уровень (в нашем случае TCP) упаковывает их в сегмент и передаёт их в сетевой уровень (IP), который каким-то путём доставляет пакет получателю. На принимающей стороне сетевой уровень доставляет эти данные до уровня TCP, что делает их доступными для получателя. TCP хранит данные для отправки в общем буфере отправки, а данные для получения – в общем буфере получения. Когда приложение готово, оно читает данные из буфера получения. Контроль потока гарантирует, что мы не отправляем новых пакетов, если буфер получения уже полон, так как получатель все равно не сможет обработать эти запросы и будет вынужден сбросить (проигнорировать) их. Для управления объемом данных для отправки через TCP, получатель объявляет своё окно (receive window), то есть объем свободного места в буфере получения. При получении нового пакета TCP отправляет ack сообщение отправителю, подтверждающее, что пакет получен корректно. Вместе с ack сообщением передаётся и размер текущего окна получения, поэтому отправитель знает, что он может или не может отправлять новые данные.",Column3:"Сократить"},{Вопросы:"Модель потоков Spring WebFlux",Ответы:"На WebFlux сервере можно увидеть следующие потоки: На оригинальном сервере Spring WebFlux существует один поток для работы сервера и несколько потоков для обработки запросов (обычно их количество равно числу ядер в процессоре). Реактивный WebClient работает в режиме event loop. Reactor обеспечивает абстракции пула потоков, которые называются scheduler’ами. Для переключения обработки на другой пул используется метод publishOn(). Планировщики (scheduler’ы) названы в соответствии со стратегией работы, например parallel для CPUориентированной параллельной обработки с ограниченным количеством потоков, elastic для I/O – с большим количеством потоков. Под капотом WebFlux трудится Reactor-Netty – обёртка над Netty с поддержкой backpressure. ReactorNetty создаёт Runtime.getRuntime().availableProcessors() * 2 потоков для использования во внутреннем EventLoopThreadPool. Если входящий запрос завершается блокирующим удалённым вызовом, то его нужно соответствующим образом обернуть, чтобы текущий поток мог вернуться в event-queue пул для обработки новых запросов. Для тяжёлых вычислительных операций имеет смысл использовать выделенный пул потоков. Это гарантирует, что EventLoop Netty будет только принимать и отправлять данные по сети, не тратя ресурсы на другие операции: @PostMapping public Mono cpuIntensiveProcessingHandler( Mono monoInput ) { return monoInput .publishOn(Schedulers.fromExecutorService(myOwnDedicatedExecutor)) .map(i -> doCpuIntensiveInImperativeStyle(i)); } Если интересен ручной контроль количества запросов, можно посмотреть в сторону метода limiRate(int n)",Column3:"Сократить"},{Вопросы:"Что такое микросервисная архитектура",Ответы:"Микросервисная архитектура — это подход, который помогает не только ускорить разработку продукта, но и сделать ее гибкой и управляемой: проект из неделимого целого превращается в систему связанных между собой блоков — сервисов."},{Вопросы:"Что такое микросервис (MS)",Ответы:"Микросервисы – это шаблон сервис-ориентированной архитектуры, в котором приложения создаются в виде наборов небольших и независимых сервисных единиц. Такой подход к проектированию сводится к разделению приложения на однофункциональные модули с четко прописанными интерфейсами. Небольшие команды, управляющие всем жизненным циклом сервиса могут независимо развертывать и обслуживать микросервисы."},{Вопросы:"Что такое Монолит",Ответы:"Монолитная архитектура — это традиционная модель программного обеспечения, которая представляет собой единый модуль, работающий автономно и независимо от других приложений. Монолитом часто называют нечто большое и неповоротливое, и эти два слова хорошо описывают монолитную архитектуру для проектирования ПО. Монолитная архитектура — это отдельная большая вычислительная сеть с единой базой кода, в которой объединены все бизнес-задачи."},{Вопросы:"Свойства микросервиса",Ответы:"1. Он небольшой.\n2. Он независимый.\n3. Он строится вокруг бизнес-потребности и использует ограниченный \nконтекст (Bounded Context).\n4. Он взаимодействует с другими микросервисами по сети на основе \nпаттерна Smart endpoints and dumb pipes.\n5. Его распределенная суть обязывает использовать подход Design for \nfailure.\n6. Централизация ограничена сверху на минимуме.\n7. Процессы его разработки и поддержки требуют автоматизации.\n8. Его развитие итерационное."},{Вопросы:"Интеграция микросервисов",Ответы:"Интеграция микросервисов обходится без ESB, как центрального промежуточного звена. Наверное, комьюнити уже натерпелось от неудачных вариантов реализации этого подхода. То, что были и удачные — не принимается в расчет. Впрочем, ESB ещё и противоречит таким критериям как децентрализация и независимость. Таким образом, сложность интеграции распределяется с центрального звена в виде ESB непосредственно на интегрируемые компоненты: «умные конечные точки». Для интеграции, как правило, используются простые текстовые протоколы, основанные на HTTP, чтобы нивелировать возможную технологическую разность микросервисов. REST-подобные протоколы являются практически стандартом. Как исключение, могут использоваться бинарные протоколы типа Java RMI или .NET Remoting. Бинарные протоколы гораздо эффективнее. Но, во-первых, появляются технологические ограничения. Во-вторых, на бинарных протоколах сложнее реализовывать шаблон Tolerant Reader, сохраняя эффективность. В-третьих, опять появляется зависимость провайдера и потребителей, поскольку они оперируют одними и теми же объектами и методами, то есть связаны по кодовой базе. Другая отличительная черта взаимодействия микросервисов — синхронные вызовы не приветствуются. Рекомендуется использовать один синхронный вызов на один запрос пользователя, или вообще отказаться от синхронных вызовов. И еще пара замечаний. \n1. Основной сложностью разбиения монолита на микросервисы является не определение их границ. Они уже должны сформироваться и устояться. Сложность заключается в том, что локальные вызовы становятся удаленными. А это влияет не только на организацию вызовов, но и на стиль взаимодействия, так как частые вызовы уже не подходят. Скорее всего, надо пересматривать сам API, делать его более крупным, а, как следствие, пересматривать логику работы компонентов. \n2. Поскольку асинхронное событийное взаимодействие — практически стандарт в микросервисной архитектуре, то надо разбираться в создании событийной архитектуры (Event Driven Architecture), а сами микросервисы должны соответствовать требованиям Reactive.",Column3:"Сократить"},{Вопросы:"Design for failure для распределенной системы",Ответы:"Одно из наиболее критичных мест в микросервисной архитектуре — необходимость разрабатывать код для распределенной системы, составные элементы которой взаимодействуют через сеть. А сеть ненадежна по своей природе: сеть может просто отказать, работать плохо или вдруг перестать пропускать какой-то тип сообщений. Поэтому микросервисы могут перестать отвечать или начать отвечать медленнее. И каждый удаленный вызов должен это учитывать, должен правильно обрабатывать разные варианты отказа, уметь ждать, уметь возвращаться к нормальной работе при восстановлении контрагента. Дополнительный уровень сложности привносит событийная архитектура, как и отладка такой системы. И поскольку сложность таких систем очень высока, то проблему решают так: \n- Не доводят систему до идеального состояния. Это очень дорого. Система отвечает необходимым нефункциональным требованиям, но в ней могут присутствовать ошибки, незначительно влияющие на ее устойчивость и производительность. \n- С другой стороны вкладываются в инфраструктуру, которая помогает быстрее устранять нештатные ситуации. Должно быть полное покрытие кода unit тестами, интеграционными и тестами производительности. Должен быть интеллектуальный мониторинг, который не только моментально показывает неработающие места, но и сигнализирует об ухудшении состояния системы с прогнозированием возможных сбоев. Должно быть продвинутое распределенное логирование, позволяющее оперативно проводить расследования.",Column3:"Сократить"},{Вопросы:"Децентрализация данных",Ответы:"Один из важнейших элементов в парадигме микросервисов.\n+ Легче реализовать Polyglot Persistence, когда база подбирается под конкретные цели.Много баз, много контекстов, как их все согласовать? Старая техника распределенных транзакций сложна и обладает низкой скоростью. Возможно это иногда можно пережить. А вот необходимость синхронного взаимодействия нескольких микросервисов не может устраивать, и это не побороть. Проблема решается нетрадиционно для монолита: отказом от постоянной согласованности данных. Добро пожаловать в мир Eventual consistency. На первых порах это вызывает волну «справедливого» гнева. Но если разобраться, то нужна ли повсеместно немедленная согласованность данных по окончании транзакции? При детальном рассмотрении значительную часть случаев можно отбросить. Где возможно, заменяют одну распределённую транзакцию серией локальных с компенсационными механизмами.",Column3:"Сократить\n\nи дополнить"},{Вопросы:"Монолит против микросервисов, плюсы и минусы",Ответы:"Микросервисный подход несет довольно много проблем. Например, организационные вопросы. Поэтому начинать путь к микросервисной архитектуре стоит с внедрения DevOps и Agile. Кроме организационных есть и чисто архитектурные. Как перейти от монолита, где всё синхронно, согласованно и едино, к распределенной событийной архитектуры, основанной на множестве мелких элементов, в которой надо учитывать возможную неконсистентность данных? Если у вас нет проблем с вашим «монолитом», то не надо их искать. Но если проблемы есть, то посмотрите на плюсы MSA, и возможно она спасет вас.\nРазбиение на независимые компоненты даёт безусловные и неоспоримые преимущества: легкое понимание контекста, гибкость развития, управления и масштабирования. Независимость и небольшой размер дают и неожиданные плюсы с точки зрения инфраструктуры. Микросервисы можно устанавливать на обычные дешевые машинки. И окажется, что даже все вместе они будут стоить на порядок меньше, но работать эффективнее той самой супермашины."},{Вопросы:"Шаблоны проектирования CQRS и Event Sourcing",Ответы:'CQRS расшифровывается как Command Query Responsibility Segregation (разделение ответственности на команды и запросы). В 1980 Бертран Мейер сформулировал термин CQS. В начале двухтысячных Грег Янг расширил и популяризовал эту концепцию к CQRS. CQRS предлагает разделять операции чтения и записи на отдельные типы операций Query и Commands.\n•        Command ориентированы на задачи, а не на данные. ("Забронировать номер в отеле", а не установить для ReservationStatus значение "зарезервировано").\n•        Command может помещаться в очередь для асинхронной обработки, а не обрабатываться синхронно.\n•        Query никогда не должен изменять базу данных. Query возвращает DTO (Data Transfer Object — один из шаблонов проектирования, используется для передачи данных между подсистемами приложения), который не инкапсулирует знания предметной области.\nНаличие отдельных моделей запросов и команд упрощает проектирование таких систем как независимых друг от друга\nДля дополнительной изоляции часто физически разделяют данные для чтения и данные для записи. В этом случае в БД для чтения можно оптимизировать ее работу так, чтобы максимально эффективно выполнять запросы. Вы можете использовать в том числе другой тип хранилища данных. Например, база данных для записи останется реляционной, а для чтения вы можете применять NoSQL или наоборот, в зависимости от бизнес-задач. Если вы пошли по пути отдельных БД для чтения и записи, они должны поддерживать синхронизацию. Обычно это реализуют с помощью событий при каждом обновлении базы данных. Обновление базы данных и публикации события должны выполняться в рамках одной транзакции'},{Вопросы:"Преимущества и недостатки CQRS",Ответы:"Преимущества CQRS\n•\tНезависимое масштабирование. CQRS позволяет раздельно масштабировать рабочие нагрузки чтения и записи, снижая риск конфликтов блокировки.\n•\tОптимизированные схемы данных. Для query применить схему, оптимизированную для запросов, а commands — другую схему, оптимизированную для обновлений.\n•\tБезопасность. Разделение операций позволит настроить более гибкую систему доступа.\n•\tРазделение проблем. Разделение операций позволяет получить более гибкие и простые в обслуживании классы. \n•\tБолее простые запросы.\n•\tНе требует 2 хранилища данных. Отдельные хранилища для query и command это одна из реализаций, а не обязательное требование\n\nНедостатки CQRS\n•\tСложность. Основная идея CQRS звучит просто. Но ее реализация может привести к усложнению проекта приложения, особенно если реализовывать его в связке с Event Sourcing (ниже).\n•\tОбмен сообщениями. Сама по себе модель CQRS не требует месседжинга, но месседж брокеры часто применяются для обработки команд и публикации событий. Это означает, нужно будет реализовывать обработку сбоев и дубликатов при передаче сообщений.\n•\tEventual consistency. Если вы разделите базы данных для чтения и записи, в базе данных для чтения могут оставаться устаревшие данные. БД для чтения должна быть up to date, чтобы отражать изменения из БД для записи, и может быть трудно трекать, когда пользователь сделал запрос на основе устаревших данных с БД для чтения.\n"},{Вопросы:"Event Sourcing",Ответы:"Event sourcing  — это архитектурный паттерн, в котором все изменения, вносимые в состояние приложения, сохраняются в той последовательности, в которой они были выполнены. Эти записи служат как источником для получения текущего состояния, так и audit-log'ом того, что происходило в системе.\nПреимущества Event Sourcing\n•        События immutable (неизменны), и их можно сохранить с помощью append-only операции. События могут раниться на фоне.\n•        Event sourcing может помочь в предотвращении конфликтов, вызванных параллельными апдейтами, тк исключает необходимость непосредственного обновления объектов в Data store. Однако доменная модель должна уметь себя защищать от запросов, которые могут вызвать несогласованное состояние.\n•        Append-only storage предоставляет audit log, который можно использовать для мониторинга событий, произошедших в Data store или проекций путем воспроизведения событий в любое время, а также упрощения тестирования и отладки системы.\n•        Каждое событие могут обрабатывать несколько задач. Это обеспечивает простую интеграцию с другими службами и системами, которые только слушают новые события, вызванные data stor'ом. Однако event sourcing events зачастую являются низкоуровневыми, из-за чего может потребоваться создание определенных событий интеграции.\nНедостатки Event Sourcing\n•        Программисты должны перестроить мышление с привычных сущностей и CRUD на только события\n•        При Event Sourcing много сил тратится на моделирование событий. После сохранения событий в сторедж они должны быть immutable, иначе история и состояние могут быть повреждены или искажены. Event Log — это исходные данные, а это значит, что необходимо очень внимательно следить за тем, чтобы они содержали всю информацию, необходимую для получения полного состояния системы на определенный момент времени. Также необходимо учитывать, что события могут интерпретироваться повторно, поскольку система со временем изменяются.\n•        Для простой бизнес логики переход на Event Sourcing может быть довольно легким, но для более сложных может стать проблемой. Так же могут возникнуть сложности интеграции с внешними системами, которые не предоставляют данные на определенный момент времени.\n•        Легкость масштабирования приводит к дополнительным проблемам в виде решения проблем и реализацией eventual consistency.\n•        Структура событий может измениться в какой-то момент. Могут возникнуть ситуации, когда исторические события должны быть обработаны текущей бизнес-логикой. И наличие расширяемой схемы событий поможет в будущем при необходимости отличать новые события от старых."},{Вопросы:"Когда следует и не следует использовать Event Sourcing",Ответы:"Когда следует использовать Event Sourcing\n•        Когда в данные необходимо записать намерение, цель или причину. Например, изменения в сущности клиента можно записать как ряд определенных типов событий, таких как Возвращение к исходному, Закрытая учетная запись или Недействительные.\n•        Когда очень важно свести к минимуму или полностью избежать конфликта операций обновления данных.\n•        Если требуется записывать происходящие события и иметь возможность воспроизвести их для восстановления определенного состояния системы, отката изменений или сохранения истории и audit-log.\n•        Когда использование событий представляет собой стандартную возможность операции приложения и требует некоторой дополнительной разработки или усилий в отношении реализации.\n•        Если нужно разбить процесс ввода или обновления данных из задач, необходимых для применения этих действий. Это может быть в целях улучшения производительности пользовательского интерфейса или распределения событий в другие прослушиватели, выполняющие определенные действия при возникновении событий.\n•        Если необходима гибкость для изменения формата материализованных моделей и данных сущности при изменении требований или —использовании в сочетании с CQRS, необходимо адаптировать модель чтения или представления с данными.\n•        Если используется в сочетании с CQRS, eventual consistency допустима при обновлении модели чтения или допустимо влияние на производительность при восстановленных сущностях и данных из потока события.\nКогда не следуюет использовать Event Sourcing\n•        Для небольших или простых доменов, систем, которые обычно хорошо взаимодействуют со стандартными механизмами управления данных CRUD.\n•        Систем, где для представления данных требуются согласованность и обновления в режиме реального времени.\n•        Систем, где для действий отката и воспроизведения не требуются определенные функции, история и audit-log.\n•        Систем, где имеется незначительный конфликт обновлений в базовых данных. Например, это системы, которые преимущественно добавляют данные, а не обновляют их.\n"},{Вопросы:"Шаблон Saga",Ответы:"Ранее мы упоминали, что распределение транзакций между микросервисами может быть проблематичным. Проще говоря, транзакция будет успешной, только если все связанные службы успешно выполнят свою часть. В случае сбоя в одной службе вся транзакция должна завершиться неудачей. Более того, в этом случае службы, которые уже внесли свой вклад, должны откатить изменения.\nВ общем, за это отвечает шаблон saga. Шаблон Saga - это последовательность локальных транзакций, которые представляют собой единую распределенную транзакцию. Каждая служба выполняет локальную транзакцию. Если локальная транзакция завершается успешно, публикуется событие или сообщение, которое запускает следующую локальную транзакцию в последовательности. В случае сбоя saga предоставляет компенсирующие транзакции, которые откатывают изменения.\nСуществует два типа реализации шаблона saga :\n•        Управление – центральный контроллер (orchestrator) управляет всеми взаимодействиями между микросервисами\n•        Хореография – децентрализованный метод трансляции событий\n"},{Вопросы:"SQL против NoSQL",Ответы:"SQL против NoSQL\nЧаще всего для проекта или службы рассматриваются две технологии: SQL и NoSQL. В принципе, это сложнее, особенно если речь идет о NoSQL. Существует множество реализаций базы данных NoSQL, а именно. Хотя в этой статье мы не будем подробно останавливаться на низкоуровневой реализации базы данных. Давайте сравним SQL и NoSQL в целом.\r"},{Вопросы:"CAP теорема",Ответы:"Теорема CAP. Теорема (известная также как теорема Брюера) — эвристическое утверждение о том, что в любой реализации распределённых вычислений возможно обеспечить не более двух из трёх следующих свойств: согласованность данных (consistency), доступность (availability), устойчивость к разделению (partition tolerance). Акроним CAP в наименовании теоремы сформирован из первых букв английских наименований этих трёх свойств.",Column3:"В CAP говорится, что в распределенной системе возможно выбрать только 2\n из 3-х свойств:\n - C (consistency) — согласованность. Каждое чтение даст вам самую\n последнюю запись.\n - A (availability) — доступность. Каждый узел (не упавший) всегда успешно\n выполняет запросы (на чтение и запись).\n - P (partition tolerance) — устойчивость к распределению. Даже если\n между узлами нет связи, они продолжают работать независимо друг от\n друга."},{Вопросы:"Неотвеченные вопросы",Ответы:0}],s=a.map((e=>({...e,id:(0,r.Z)()}))),o=()=>s,l=e=>s.find((n=>n.id===e))},4611:(e,n,t)=>{"use strict";t(6992),t(8674),t(7727);var r=t(9963),a=t(6252),s=t(2262),o=t(9810);const l=(0,a.aZ)({__name:"App",setup(e){return(e,n)=>((0,a.wg)(),(0,a.j4)((0,s.SU)(o.dr),null,{default:(0,a.w5)((()=>[(0,a.Wm)((0,s.SU)(o.jP))])),_:1}))}}),i=l,u=i;t(3948);var c=t(1089),b=t(3577);const p=e=>((0,a.dD)("data-v-16f1829e"),e=e(),(0,a.Cn)(),e),v=p((()=>(0,a._)("div",{slot:"start"},null,-1))),d=(0,a.aZ)({__name:"MessageListItem",props:{message:Object},setup(e){return(n,t)=>e.message?((0,a.wg)(),(0,a.j4)((0,s.SU)(o.Ie),{key:0,routerLink:"/message/"+e.message.id,detail:!1,class:"list-item"},{default:(0,a.w5)((()=>[v,(0,a.Wm)((0,s.SU)(o.Q$),{class:"ion-text-wrap"},{default:(0,a.w5)((()=>[(0,a._)("h2",null,(0,b.zw)(e.message["Вопросы"]),1),(0,a._)("p",null,(0,b.zw)(e.message["Ответы"]),1)])),_:1})])),_:1},8,["routerLink"])):(0,a.kq)("",!0)}});var m=t(3744);const S=(0,m.Z)(d,[["__scopeId","data-v-16f1829e"]]),O=S;var h=t(9594);const f=(0,a.aZ)({components:{IonSearchbar:o.VI},data(){return{results:[],questions:[]}},methods:{handleChange(e){var n;const t=null===(n=e.target.value)||void 0===n?void 0:n.toLowerCase();this.results=this.questions.filter((e=>e["Вопросы"].toLowerCase().indexOf(t)>-1))}},created(){this.questions=(0,h._)(),this.results=this.questions}}),C=(0,a.aZ)({...f,__name:"HomePage",setup(e){return(e,n)=>((0,a.wg)(),(0,a.j4)((0,s.SU)(o._i),null,{default:(0,a.w5)((()=>[(0,a.Wm)((0,s.SU)(o.Gu),{translucent:!0},{default:(0,a.w5)((()=>[(0,a.Wm)((0,s.SU)(o.sr),null,{default:(0,a.w5)((()=>[(0,a.Wm)((0,s.SU)(o.VI),{onIonChange:n[0]||(n[0]=n=>e.handleChange(n)),"show-clear-button":"always"})])),_:1})])),_:1}),(0,a.Wm)((0,s.SU)(o.W2),{fullscreen:!0},{default:(0,a.w5)((()=>[(0,a.Wm)((0,s.SU)(o.nJ),{slot:"fixed",onIonRefresh:n[1]||(n[1]=n=>e.refresh(n))},{default:(0,a.w5)((()=>[(0,a.Wm)((0,s.SU)(o.Wo))])),_:1}),(0,a.Wm)((0,s.SU)(o.Gu),{collapse:"condense"},{default:(0,a.w5)((()=>[(0,a.Wm)((0,s.SU)(o.sr),null,{default:(0,a.w5)((()=>[(0,a.Wm)((0,s.SU)(o.wd),{size:"large"},{default:(0,a.w5)((()=>[(0,a.Uk)("Inbox")])),_:1})])),_:1})])),_:1}),(0,a.Wm)((0,s.SU)(o.q_),null,{default:(0,a.w5)((()=>[((0,a.wg)(!0),(0,a.iD)(a.HY,null,(0,a.Ko)(e.results,(e=>((0,a.wg)(),(0,a.j4)(O,{key:e.id,message:e},null,8,["message"])))),128))])),_:1})])),_:1})])),_:1}))}}),g=C,y=g,R=[{path:"/",redirect:"/home"},{path:"/home",name:"Home",component:y},{path:"/message/:id",component:()=>t.e(95).then(t.bind(t,8095))}],I=(0,c.p7)({history:(0,c.PO)(""),routes:R}),x=I;t(8851),t(1292),t(1633),t(1045),t(6187),t(2299),t(3423),t(4687),t(9147),t(6250);const M=(0,r.ri)(u).use(o.oX).use(x);M.config.compilerOptions.isCustomElement=e=>e.startsWith("ion-"),x.isReady().then((()=>{M.mount("#app")}))}},n={};function t(r){var a=n[r];if(void 0!==a)return a.exports;var s=n[r]={exports:{}};return e[r](s,s.exports,t),s.exports}t.m=e,(()=>{var e=[];t.O=(n,r,a,s)=>{if(!r){var o=1/0;for(c=0;c<e.length;c++){for(var[r,a,s]=e[c],l=!0,i=0;i<r.length;i++)(!1&s||o>=s)&&Object.keys(t.O).every((e=>t.O[e](r[i])))?r.splice(i--,1):(l=!1,s<o&&(o=s));if(l){e.splice(c--,1);var u=a();void 0!==u&&(n=u)}}return n}s=s||0;for(var c=e.length;c>0&&e[c-1][2]>s;c--)e[c]=e[c-1];e[c]=[r,a,s]}})(),(()=>{t.d=(e,n)=>{for(var r in n)t.o(n,r)&&!t.o(e,r)&&Object.defineProperty(e,r,{enumerable:!0,get:n[r]})}})(),(()=>{t.f={},t.e=e=>Promise.all(Object.keys(t.f).reduce(((n,r)=>(t.f[r](e,n),n)),[]))})(),(()=>{t.u=e=>"js/"+e+"-legacy."+{78:"223c07ee",95:"57e848df",261:"97765ef2",338:"c83c6dc3",453:"c5cd1f79",541:"ef6a56fd",544:"6a04cced",576:"699059d2",753:"9ddfd99c",775:"8e84ca02",823:"e71f9e3d",990:"d6c61c11"}[e]+".js"})(),(()=>{t.miniCssF=e=>"css/"+e+".f1861709.css"})(),(()=>{t.g=function(){if("object"===typeof globalThis)return globalThis;try{return this||new Function("return this")()}catch(e){if("object"===typeof window)return window}}()})(),(()=>{t.o=(e,n)=>Object.prototype.hasOwnProperty.call(e,n)})(),(()=>{var e={},n="exam-answers:";t.l=(r,a,s,o)=>{if(e[r])e[r].push(a);else{var l,i;if(void 0!==s)for(var u=document.getElementsByTagName("script"),c=0;c<u.length;c++){var b=u[c];if(b.getAttribute("src")==r||b.getAttribute("data-webpack")==n+s){l=b;break}}l||(i=!0,l=document.createElement("script"),l.charset="utf-8",l.timeout=120,t.nc&&l.setAttribute("nonce",t.nc),l.setAttribute("data-webpack",n+s),l.src=r),e[r]=[a];var p=(n,t)=>{l.onerror=l.onload=null,clearTimeout(v);var a=e[r];if(delete e[r],l.parentNode&&l.parentNode.removeChild(l),a&&a.forEach((e=>e(t))),n)return n(t)},v=setTimeout(p.bind(null,void 0,{type:"timeout",target:l}),12e4);l.onerror=p.bind(null,l.onerror),l.onload=p.bind(null,l.onload),i&&document.head.appendChild(l)}}})(),(()=>{t.r=e=>{"undefined"!==typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})}})(),(()=>{t.p=""})(),(()=>{if("undefined"!==typeof document){var e=(e,n,t,r,a)=>{var s=document.createElement("link");s.rel="stylesheet",s.type="text/css";var o=t=>{if(s.onerror=s.onload=null,"load"===t.type)r();else{var o=t&&("load"===t.type?"missing":t.type),l=t&&t.target&&t.target.href||n,i=new Error("Loading CSS chunk "+e+" failed.\n("+l+")");i.code="CSS_CHUNK_LOAD_FAILED",i.type=o,i.request=l,s.parentNode.removeChild(s),a(i)}};return s.onerror=s.onload=o,s.href=n,t?t.parentNode.insertBefore(s,t.nextSibling):document.head.appendChild(s),s},n=(e,n)=>{for(var t=document.getElementsByTagName("link"),r=0;r<t.length;r++){var a=t[r],s=a.getAttribute("data-href")||a.getAttribute("href");if("stylesheet"===a.rel&&(s===e||s===n))return a}var o=document.getElementsByTagName("style");for(r=0;r<o.length;r++){a=o[r],s=a.getAttribute("data-href");if(s===e||s===n)return a}},r=r=>new Promise(((a,s)=>{var o=t.miniCssF(r),l=t.p+o;if(n(o,l))return a();e(r,l,null,a,s)})),a={143:0};t.f.miniCss=(e,n)=>{var t={95:1};a[e]?n.push(a[e]):0!==a[e]&&t[e]&&n.push(a[e]=r(e).then((()=>{a[e]=0}),(n=>{throw delete a[e],n})))}}})(),(()=>{var e={143:0};t.f.j=(n,r)=>{var a=t.o(e,n)?e[n]:void 0;if(0!==a)if(a)r.push(a[2]);else{var s=new Promise(((t,r)=>a=e[n]=[t,r]));r.push(a[2]=s);var o=t.p+t.u(n),l=new Error,i=r=>{if(t.o(e,n)&&(a=e[n],0!==a&&(e[n]=void 0),a)){var s=r&&("load"===r.type?"missing":r.type),o=r&&r.target&&r.target.src;l.message="Loading chunk "+n+" failed.\n("+s+": "+o+")",l.name="ChunkLoadError",l.type=s,l.request=o,a[1](l)}};t.l(o,i,"chunk-"+n,n)}},t.O.j=n=>0===e[n];var n=(n,r)=>{var a,s,[o,l,i]=r,u=0;if(o.some((n=>0!==e[n]))){for(a in l)t.o(l,a)&&(t.m[a]=l[a]);if(i)var c=i(t)}for(n&&n(r);u<o.length;u++)s=o[u],t.o(e,s)&&e[s]&&e[s][0](),e[s]=0;return t.O(c)},r=self["webpackChunkexam_answers"]=self["webpackChunkexam_answers"]||[];r.forEach(n.bind(null,0)),r.push=n.bind(null,r.push.bind(r))})();var r=t.O(void 0,[998],(()=>t(4611)));r=t.O(r)})();
//# sourceMappingURL=app-legacy.871cb4cb.js.map